#!/usr/bin/env python3
"""
Simple Voice Agent for HKUST-GZ
Author: FractFlow Team
Brief: Simplified voice assistant without web search functionality
Supports both default voice and Ni voice modes
"""

import asyncio
import os
import sys
import json
import threading
import queue
import time
import numpy as np
import base64

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False
    pass  # PyAudioæœªå®‰è£…è­¦å‘Šï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰

from tools.core.qwen_realtime_voice.qwen_realtime_voice_mcp import QwenRealtimeVoiceClient
from .voice_config import setup_api_keys, get_voice_session_config

class SimpleVoiceAgent(QwenRealtimeVoiceClient):
    """æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹ - æ”¯æŒåŒéŸ³è‰²æ¨¡å¼"""
    
    def __init__(self, api_key=None, voice_mode="default"):
        super().__init__(api_key)
        
        # éŸ³è‰²æ¨¡å¼ï¼šdefault æˆ– ni
        self.voice_mode = voice_mode
        
        # æ ¸å¿ƒçŠ¶æ€
        self.is_ai_speaking = False
        self.interrupt_detected = False
        self.user_speaking = False
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = queue.Queue(maxsize=50)
        
        # æ–‡æœ¬ç´¯ç§¯
        self.current_ai_response = ""
        self.last_user_input_shown = False
        
        # TTSæ¸è¿›å¼æ’­æ”¾ï¼ˆå€ªæ ¡æ¨¡å¼ï¼‰
        self.tts_queue = queue.Queue()  # TTSæ’­æ”¾é˜Ÿåˆ—
        self.tts_thread = None  # TTSå·¥ä½œçº¿ç¨‹
        self.sentence_buffer = ""  # å¥å­ç¼“å†²åŒº
        self.is_tts_playing = False  # TTSæ’­æ”¾çŠ¶æ€
        self.tts_stop_event = threading.Event()  # TTSåœæ­¢ä¿¡å·
        self.tts_interrupt_event = threading.Event()  # TTSå¿«é€Ÿä¸­æ–­ä¿¡å·
        
        # åˆ†å¥é…ç½®
        self.sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']
        self.min_sentence_length = 8  # æœ€å°å¥å­é•¿åº¦
        self.max_sentence_length = 150  # æœ€å¤§å¥å­é•¿åº¦
        
        # æ”¹è¿›çš„éŸ³é‡æ£€æµ‹
        self.volume_threshold = 25  # æé«˜åŸºç¡€é˜ˆå€¼
        self.volume_samples = []  # éŸ³é‡é‡‡æ ·ç¼“å†²åŒº
        self.volume_buffer_size = 3  # è¿ç»­æ€§æ£€æµ‹çª—å£
        self.background_noise_level = 0  # èƒŒæ™¯å™ªéŸ³åŸºçº¿
        self.calibration_samples = 0  # æ ¡å‡†é‡‡æ ·è®¡æ•°
        
        # åˆå§‹åŒ–å®Œæˆï¼ˆç§»é™¤printä»¥é¿å…MCPé€šä¿¡å¹²æ‰°ï¼‰
    
    async def _configure_session(self):
        """é…ç½®ä¼šè¯ - æ ¹æ®voice_modeé€‰æ‹©é…ç½®"""
        config = get_voice_session_config(self.voice_mode)
        await self.websocket.send(json.dumps({"type": "session.update", "session": config}))

    def _recording_worker(self):
        """å½•éŸ³å·¥ä½œçº¿ç¨‹ - å¢å¼ºç‰ˆéŸ³é‡æ£€æµ‹"""
        # å½•éŸ³çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                audio_data = self.input_stream.read(1024, exception_on_overflow=False)
                
                # æ”¹è¿›çš„éŸ³é‡æ£€æµ‹
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                if len(audio_array) > 0:
                    volume = np.sqrt(np.mean(audio_array.astype(np.float64)**2))
                    
                    # åŠ¨æ€èƒŒæ™¯å™ªéŸ³æ ¡å‡†ï¼ˆå‰50ä¸ªé‡‡æ ·ï¼‰
                    if self.calibration_samples < 50:
                        self.background_noise_level = (self.background_noise_level * self.calibration_samples + volume) / (self.calibration_samples + 1)
                        self.calibration_samples += 1
                    
                    # åŠ¨æ€é˜ˆå€¼ï¼šèƒŒæ™¯å™ªéŸ³ + å›ºå®šå¢é‡
                    adaptive_threshold = max(self.volume_threshold, self.background_noise_level + 15)
                    
                    # éŸ³é‡ç¼“å†²åŒºç”¨äºè¿ç»­æ€§æ£€æµ‹
                    self.volume_samples.append(volume > adaptive_threshold)
                    if len(self.volume_samples) > self.volume_buffer_size:
                        self.volume_samples.pop(0)
                    
                    # è¿ç»­æ€§éªŒè¯ï¼šè‡³å°‘2/3çš„é‡‡æ ·è¶…è¿‡é˜ˆå€¼
                    speaking_confidence = sum(self.volume_samples) / len(self.volume_samples)
                    
                    # æ£€æµ‹ç”¨æˆ·è¯´è¯
                    if speaking_confidence >= 0.6 and len(self.volume_samples) >= 2:
                        if not self.user_speaking:
                            self.user_speaking = True
                            if not self.last_user_input_shown:
                                print(f"\nğŸ¤ [æ­£åœ¨å¬å–æ‚¨çš„é—®é¢˜...]", flush=True)
                        
                        # å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œåˆ™æ‰“æ–­ï¼ˆå¤šçº§æ‰“æ–­ï¼‰
                        if self.is_ai_speaking or self.is_tts_playing:
                            self._interrupt_ai_multilevel()
                    
                    # å‘é€éŸ³é¢‘åˆ°å¤„ç†é˜Ÿåˆ—
                    if not self.audio_queue.full():
                        self.audio_queue.put(audio_data)
                
                time.sleep(0.005)  # æé«˜æ£€æµ‹é¢‘ç‡åˆ°5ms
                
            except Exception as e:
                if self.is_recording:
                    print(f"\nâŒ å½•éŸ³é”™è¯¯: {e}")
                break
        
        print(f"\nğŸ›‘ å½•éŸ³çº¿ç¨‹ç»“æŸ")
    
    def _interrupt_ai_multilevel(self):
        """å¤šçº§æ‰“æ–­AI - å¿«é€Ÿå“åº”æœºåˆ¶"""
        if self.is_ai_speaking or self.is_tts_playing:
            # ç¬¬ä¸€çº§ï¼šç«‹å³è®¾ç½®ä¸­æ–­ä¿¡å·
            self.interrupt_detected = True
            self.tts_interrupt_event.set()
            
            # ç¬¬äºŒçº§ï¼šç«‹å³åœæ­¢å€ªæ ¡TTSæ’­æ”¾
            if self.voice_mode == "ni":
                try:
                    from tools.core.guang_voice_assistant.ni_voice_clone_client.main import set_interrupt
                    set_interrupt()  # ç«‹å³ä¸­æ–­TTSæ’­æ”¾
                except ImportError:
                    pass
            
            # ç¬¬ä¸‰çº§ï¼šæ¸…ç©ºæ‰€æœ‰ç¼“å†²åŒºå’Œé˜Ÿåˆ—
            self.is_ai_speaking = False
            self.is_tts_playing = False
            
            # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
            while not self.audio_buffer.empty():
                try:
                    self.audio_buffer.get_nowait()
                except:
                    break
            
            # æ¸…ç©ºTTSé˜Ÿåˆ—
            while not self.tts_queue.empty():
                try:
                    self.tts_queue.get_nowait()
                except:
                    break
            
            # é‡ç½®å¥å­ç¼“å†²åŒº
            self.sentence_buffer = ""
            
            # æ˜¾ç¤ºæ‰“æ–­ä¿¡æ¯
            if self.current_ai_response.strip():
                print(f"\nğŸ’¬ AI: {self.current_ai_response.strip()} [è¢«å¿«é€Ÿæ‰“æ–­]")
            else:
                print(f"\nâš¡ [AIè¢«å¿«é€Ÿæ‰“æ–­]")
            
            # é‡ç½®å›ç­”ç´¯ç§¯
            self.current_ai_response = ""

    def _interrupt_ai(self):
        """æ‰“æ–­AI - å…¼å®¹æ—§æ¥å£ï¼Œé‡å®šå‘åˆ°å¤šçº§æ‰“æ–­"""
        self._interrupt_ai_multilevel()
    
    def _processing_worker(self):
        """å¤„ç†å·¥ä½œçº¿ç¨‹"""
        # å¤„ç†çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            loop.run_until_complete(self._async_processing())
        finally:
            loop.close()
    
    async def _async_processing(self):
        """å¼‚æ­¥å¤„ç†"""
        while self.is_recording and not self.stop_event.is_set():
            try:
                # å‘é€å–æ¶ˆä¿¡å·ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if self.interrupt_detected:
                    await self._send_cancel()
                    self.interrupt_detected = False
                
                # å‘é€éŸ³é¢‘
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get_nowait()
                    await self._send_audio_chunk(audio_data)
                
                # å¤„ç†å“åº”
                await self._handle_responses()
                await asyncio.sleep(0.02)
                
            except Exception as e:
                if "websocket" not in str(e).lower():
                    print(f"\nâŒ å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.1)
    
    async def _send_cancel(self):
        """å‘é€å–æ¶ˆä¿¡å·"""
        try:
            cancel_msg = {"type": "response.cancel"}
            await self.websocket.send(json.dumps(cancel_msg))
            print("\rğŸš« [å–æ¶ˆä¿¡å·å·²å‘é€]", end="", flush=True)
        except:
            pass
    
    async def _handle_responses(self):
        """å¤„ç†AIå“åº” - æ”¯æŒå€ªæ ¡TTSæ¨¡å¼"""
        try:
            message = await asyncio.wait_for(self.websocket.recv(), timeout=0.01)
            data = json.loads(message)
            response_type = data.get("type", "")
            
            if response_type == "response.audio.delta":
                # AIéŸ³é¢‘å›ç­” - é»˜è®¤æ¨¡å¼æ’­æ”¾ï¼Œå€ªæ ¡æ¨¡å¼è·³è¿‡
                audio_base64 = data.get("delta", "")
                if audio_base64 and not self.interrupt_detected:
                    if self.voice_mode == "default":
                        # é»˜è®¤æ¨¡å¼ï¼šç›´æ¥æ’­æ”¾åƒé—®éŸ³é¢‘
                        self.audio_buffer.put(audio_base64)
                    # å€ªæ ¡æ¨¡å¼ï¼šè·³è¿‡éŸ³é¢‘ï¼Œç­‰å¾…æ–‡æœ¬å®Œæˆåç”¨TTSæ’­æ”¾
                    if not self.is_ai_speaking:
                        self.is_ai_speaking = True
                        print("\nğŸ¤– [AIæ­£åœ¨å›ç­”...]")
            
            elif response_type == "response.audio_transcript.delta":
                # AIæ–‡æœ¬å›ç­”ï¼ˆç´¯ç§¯æ˜¾ç¤º+æµå¼TTSï¼‰
                transcript = data.get("delta", "")
                if transcript.strip() and not self.interrupt_detected:
                    self.current_ai_response += transcript
                    
                    # å€ªæ ¡æ¨¡å¼ï¼šæµå¼åˆ†å¥TTS
                    if self.voice_mode == "ni":
                        self.sentence_buffer += transcript
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¥å­å¯ä»¥æ’­æ”¾
                        sentences = self._extract_sentences(self.sentence_buffer)
                        if len(sentences) > 1:  # è‡³å°‘æœ‰ä¸€ä¸ªå®Œæ•´å¥å­
                            # æ’­æ”¾é™¤æœ€åä¸€ä¸ªå¥å­å¤–çš„æ‰€æœ‰å¥å­
                            for sentence in sentences[:-1]:
                                self._queue_sentence_tts(sentence)
                            # ä¿ç•™æœ€åä¸€ä¸ªæœªå®Œæˆçš„å¥å­
                            self.sentence_buffer = sentences[-1] if sentences else ""
            
            elif response_type == "response.audio_transcript.done":
                # AIæ–‡æœ¬å›ç­”å®Œæˆï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹å¹¶æ’­æ”¾å‰©ä½™TTS
                if not self.interrupt_detected and self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()}")
                    
                    # å€ªæ ¡æ¨¡å¼ï¼šæ’­æ”¾å‰©ä½™çš„å¥å­ç¼“å†²åŒº
                    if self.voice_mode == "ni" and self.sentence_buffer.strip():
                        self._queue_sentence_tts(self.sentence_buffer.strip())
                        self.sentence_buffer = ""
                    
                    self.current_ai_response = ""
            
            elif response_type == "response.done":
                # AIå›ç­”å®Œæˆ
                self.is_ai_speaking = False
                self.last_user_input_shown = False  # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹æ¬¡ç”¨æˆ·è¾“å…¥
                if not self.interrupt_detected:
                    print("âœ… [AIå›ç­”å®Œæˆ]\n")
            
            elif response_type == "response.cancelled":
                # AIå›ç­”è¢«å–æ¶ˆ
                self.is_ai_speaking = False
                if self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()} [å·²å–æ¶ˆ]")
                else:
                    print("ğŸš« [AIå›ç­”å·²å–æ¶ˆ]")
                self.current_ai_response = ""
            
            elif response_type == "conversation.item.input_audio_transcription.completed":
                # ç”¨æˆ·è¯­éŸ³è¯†åˆ«å®Œæˆ
                transcript = data.get("transcript", "")
                if transcript.strip():
                    self.user_speaking = False
                    self.last_user_input_shown = True
                    print(f"ğŸ‘¤ æ‚¨è¯´: {transcript}")
            
            elif response_type == "error":
                error_msg = data.get("error", {}).get("message", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ é”™è¯¯: {error_msg}")
        
        except asyncio.TimeoutError:
            # æ­£å¸¸æƒ…å†µï¼Œæ²¡æœ‰æ–°æ¶ˆæ¯
            pass
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        except Exception as e:
            if "websocket" not in str(e).lower():
                print(f"âŒ å“åº”å¤„ç†é”™è¯¯: {e}")
    
    def _audio_playback_worker(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
        # éŸ³é¢‘æ’­æ”¾çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                if not self.audio_buffer.empty():
                    audio_base64 = self.audio_buffer.get(timeout=0.1)
                    if not self.interrupt_detected:
                        self._play_audio(audio_base64)
                else:
                    time.sleep(0.01)
            except queue.Empty:
                time.sleep(0.01)
            except Exception as e:
                print(f"âŒ æ’­æ”¾é”™è¯¯: {e}")
    
    def _play_audio(self, audio_base64):
        """æ’­æ”¾éŸ³é¢‘ - ä»…é»˜è®¤æ¨¡å¼ä½¿ç”¨"""
        try:
            if not HAS_PYAUDIO or self.interrupt_detected or self.voice_mode == "ni":
                return  # å€ªæ ¡æ¨¡å¼ä¸æ’­æ”¾åƒé—®éŸ³é¢‘
            
            audio_data = base64.b64decode(audio_base64)
            
            if not self.output_stream:
                self.output_stream = self.pyaudio_instance.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=16000,
                    output=True,
                    frames_per_buffer=1024
                )
            
            # æ’­æ”¾éŸ³é¢‘
            if audio_data:
                self.output_stream.write(audio_data, exception_on_underflow=False)
        
        except Exception as e:
            if not self.interrupt_detected:
                print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")
    
    def _extract_sentences(self, text):
        """æ™ºèƒ½åˆ†å¥æå–"""
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            
            # æ£€æµ‹å¥å­ç»“æŸ
            if char in self.sentence_endings:
                # æ£€æŸ¥å¥å­é•¿åº¦æ˜¯å¦åˆç†
                if len(current_sentence.strip()) >= self.min_sentence_length:
                    sentences.append(current_sentence.strip())
                    current_sentence = ""
                # å¦‚æœå¤ªçŸ­ï¼Œç»§ç»­ç´¯ç§¯
            
            # é˜²æ­¢å•å¥è¿‡é•¿
            elif len(current_sentence) >= self.max_sentence_length:
                # å¯»æ‰¾æœ€è¿‘çš„æ ‡ç‚¹ç¬¦å·åˆ†å‰²
                for i in range(len(current_sentence) - 1, -1, -1):
                    if current_sentence[i] in ['ï¼Œ', ',', 'ï¼›', ';', 'ï¼š', ':']:
                        sentences.append(current_sentence[:i+1].strip())
                        current_sentence = current_sentence[i+1:]
                        break
                else:
                    # æ²¡æ‰¾åˆ°æ ‡ç‚¹ï¼Œå¼ºåˆ¶åˆ†å‰²
                    sentences.append(current_sentence.strip())
                    current_sentence = ""
        
        # å¤„ç†å‰©ä½™æ–‡æœ¬
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        return sentences
    
    def _start_tts_worker(self):
        """å¯åŠ¨TTSå·¥ä½œçº¿ç¨‹"""
        if self.voice_mode == "ni" and (self.tts_thread is None or not self.tts_thread.is_alive()):
            self.tts_stop_event.clear()
            self.tts_thread = threading.Thread(target=self._tts_worker, daemon=True)
            self.tts_thread.start()
    
    def _stop_tts_worker(self):
        """åœæ­¢TTSå·¥ä½œçº¿ç¨‹"""
        if self.tts_thread and self.tts_thread.is_alive():
            self.tts_stop_event.set()
            self.tts_interrupt_event.set()  # è®¾ç½®å¿«é€Ÿä¸­æ–­ä¿¡å·
            
            # ç«‹å³åœæ­¢å€ªæ ¡TTSæ’­æ”¾
            if self.voice_mode == "ni":
                try:
                    from tools.core.guang_voice_assistant.ni_voice_clone_client.main import set_interrupt
                    set_interrupt()
                except ImportError:
                    pass
            
            # æ¸…ç©ºé˜Ÿåˆ—
            while not self.tts_queue.empty():
                try:
                    self.tts_queue.get_nowait()
                except:
                    break
    
    def _tts_worker(self):
        """TTSé˜Ÿåˆ—å¤„ç†å™¨ - å¢å¼ºä¸­æ–­å“åº”"""
        try:
            # å¯¼å…¥å€ªæ ¡TTSåŠŸèƒ½
            from tools.core.guang_voice_assistant.ni_voice_clone_client.main import play_ni_voice
            
            while not self.tts_stop_event.is_set():
                try:
                    # æ£€æŸ¥å¿«é€Ÿä¸­æ–­ä¿¡å·
                    if self.tts_interrupt_event.is_set():
                        # æ¸…ç©ºé˜Ÿåˆ—å¹¶é‡ç½®ä¿¡å·
                        while not self.tts_queue.empty():
                            try:
                                self.tts_queue.get_nowait()
                                self.tts_queue.task_done()
                            except:
                                break
                        self.tts_interrupt_event.clear()
                        continue
                    
                    # ä»é˜Ÿåˆ—è·å–å¥å­
                    sentence = self.tts_queue.get(timeout=0.2)  # å‡å°‘è¶…æ—¶æ—¶é—´æé«˜å“åº”æ€§
                    
                    # å†æ¬¡æ£€æŸ¥ä¸­æ–­ä¿¡å·
                    if sentence and not self.interrupt_detected and not self.tts_interrupt_event.is_set():
                        self.is_tts_playing = True
                        play_ni_voice(sentence)
                        self.is_tts_playing = False
                    
                    # æ ‡è®°ä»»åŠ¡å®Œæˆ
                    self.tts_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"âš ï¸ TTSæ’­æ”¾é”™è¯¯: {e}")
                    self.is_tts_playing = False
                    
        except ImportError:
            print("âš ï¸ å€ªæ ¡TTSæ¨¡å—ä¸å¯ç”¨")
    
    def _queue_sentence_tts(self, sentence):
        """å°†å¥å­åŠ å…¥TTSé˜Ÿåˆ—"""
        if self.voice_mode == "ni" and sentence.strip():
            try:
                self.tts_queue.put_nowait(sentence.strip())
                if not self.is_ai_speaking:
                    self.is_ai_speaking = True
                    print("ğŸ“ [å€ªæ ¡é•¿å¼€å§‹å›ç­”...]")
            except queue.Full:
                print("âš ï¸ TTSé˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡å¥å­")
    
    def _play_ni_tts(self, text):
        """æ’­æ”¾å€ªæ ¡TTSéŸ³é¢‘ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        if not text.strip():
            return
            
        try:
            # åˆ†å¥å¤„ç†
            sentences = self._extract_sentences(text)
            for sentence in sentences:
                self._queue_sentence_tts(sentence)
                
        except Exception as e:
            print(f"âš ï¸ åˆ†å¥å¤„ç†å¤±è´¥: {e}ï¼Œé™çº§ä¸ºæ–‡æœ¬æ˜¾ç¤º")

async def run_simple_voice_agent(voice_mode="default"):
    """è¿è¡Œæç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹"""
    mode_name = "é»˜è®¤éŸ³è‰²ç‰ˆ" if voice_mode == "default" else "å€ªæ ¡éŸ³è‰²ç‰ˆï¼ˆæµå¼TTSï¼‰"
    print(f"ğŸ« é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ - {mode_name}")
    print("ğŸ“ HKUST-GZ Intelligent Voice Assistant - Simple Edition")
    print("=" * 60)
    
    setup_api_keys()
    api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("QWEN_API_KEY")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return
    
    agent = SimpleVoiceAgent(api_key, voice_mode)
    
    try:
        # æ­£åœ¨è¿æ¥åƒé—®Omni APIï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        await agent.connect()
        
        result = agent.start_recording()
        if not result["success"]:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {result['error']}")
            return
        
        # å¯åŠ¨TTSå·¥ä½œçº¿ç¨‹ï¼ˆå€ªæ ¡æ¨¡å¼ï¼‰
        if voice_mode == "ni":
            agent._start_tts_worker()
            print("ğŸ“ [å€ªæ ¡TTSå¼•æ“å·²å¯åŠ¨]")
        
        print(f"\nâœ… {mode_name}è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("\nğŸ¤ æ ¸å¿ƒåŠŸèƒ½:")
        print("   â€¢ å®æ—¶è¯­éŸ³å¯¹è¯")
        print("   â€¢ âš¡ æ™ºèƒ½å¿«é€Ÿæ‰“æ–­ï¼ˆ100-300mså“åº”ï¼‰")
        print("   â€¢ ğŸ”Š åŠ¨æ€éŸ³é‡æ£€æµ‹+èƒŒæ™¯å™ªéŸ³é€‚åº”")
        print("   â€¢ å®æ—¶AIå›ç­”å­—å¹•")
        if voice_mode == "ni":
            print("   â€¢ ğŸš€ æµå¼TTSæ’­æ”¾ï¼ˆå¤§å¹…æå‡å“åº”é€Ÿåº¦ï¼‰")
            print("   â€¢ ğŸ›‘ å¤šçº§æ‰“æ–­æœºåˆ¶ï¼ˆç«‹å³åœæ­¢éŸ³é¢‘ï¼‰")
        print("   â€¢ æŒ‰ Ctrl+C é€€å‡º")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ ç›´æ¥è¯´è¯æé—®")
        print("   â€¢ ğŸ¯ å¼€å§‹è¯´è¯æ—¶è‡ªåŠ¨å¿«é€Ÿæ‰“æ–­AIï¼ˆæé€Ÿå“åº”ï¼‰")
        if voice_mode == "ni":
            print("   â€¢ å€ªæ ¡å£°éŸ³ä¼šåœ¨å¥å­ç”Ÿæˆæ—¶ç«‹å³æ’­æ”¾")
        print("   â€¢ ç­‰å¾…AIå›ç­”å®Œæˆåç»§ç»­å¯¹è¯")
        print("=" * 60)
        print("\nğŸ”§ æ­£åœ¨æ ¡å‡†èƒŒæ™¯å™ªéŸ³...")
        print("ğŸ¤ å¼€å§‹å¯¹è¯å§ï¼ˆå‰å‡ ç§’ç³»ç»Ÿä¼šè‡ªåŠ¨é€‚åº”ç¯å¢ƒéŸ³é‡ï¼‰...")
        
        # ä¸»å¾ªç¯
        while True:
            await asyncio.sleep(1)
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            if not agent.is_recording:
                print("\nâš ï¸ æ£€æµ‹åˆ°å½•éŸ³ç³»ç»Ÿå·²åœæ­¢")
                break
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸»åŠ¨é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        print("\nğŸ§¹ æ­£åœ¨å…³é—­è¯­éŸ³åŠ©æ‰‹...")
        
        # åœæ­¢TTSå·¥ä½œçº¿ç¨‹
        if voice_mode == "ni":
            agent._stop_tts_worker()
            print("ğŸ“ [å€ªæ ¡TTSå¼•æ“å·²åœæ­¢]")
        
        await agent.disconnect()
        print("âœ… è¯­éŸ³åŠ©æ‰‹å·²å®‰å…¨å…³é—­")
        print("ğŸ“ æ„Ÿè°¢ä½¿ç”¨HKUST-GZæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼")

if __name__ == "__main__":
    import sys
    voice_mode = sys.argv[1] if len(sys.argv) > 1 else "default"
    asyncio.run(run_simple_voice_agent(voice_mode)) 