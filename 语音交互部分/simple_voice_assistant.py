#!/usr/bin/env python3
"""
é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ - æç®€ç‰ˆ
HKUST-GZ Intelligent Voice Assistant - Simple Edition
åªåŒ…å«æ ¸å¿ƒåŠŸèƒ½ï¼šå®æ—¶è¯­éŸ³äº¤äº’ + åŸºæœ¬æ‰“æ–­ + ç½‘ç»œæœç´¢
"""

import asyncio
import os
import sys
import json
import threading
import queue
import time
import numpy as np
import base64
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False
    print("âš ï¸  PyAudioæœªå®‰è£…ï¼Œå°†æ— æ³•æ’­æ”¾éŸ³é¢‘")

# æ·»åŠ websearchæ¨¡å—å¯¼å…¥
sys.path.insert(0, os.path.join(parent_dir, 'tools', 'core', 'websearch', 'src'))
try:
    from core_logic import web_search_and_browse
    HAS_WEBSEARCH = True
    print("âœ… ç½‘ç»œæœç´¢åŠŸèƒ½å·²åŠ è½½")
except ImportError as e:
    HAS_WEBSEARCH = False
    print(f"âš ï¸  ç½‘ç»œæœç´¢åŠŸèƒ½æœªåŠ è½½: {e}")

from tools.core.qwen_realtime_voice.qwen_realtime_voice_mcp import QwenRealtimeVoiceClient
from voice_config import setup_api_keys, get_voice_session_config

class SimpleVoiceAssistant(QwenRealtimeVoiceClient):
    """æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½ + ç½‘ç»œæœç´¢"""
    
    def __init__(self, api_key=None):
        super().__init__(api_key)
        
        # æ ¸å¿ƒçŠ¶æ€
        self.is_ai_speaking = False
        self.interrupt_detected = False
        self.user_speaking = False
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = queue.Queue(maxsize=50)
        
        # æ–‡æœ¬ç´¯ç§¯
        self.current_ai_response = ""
        self.last_user_input_shown = False
        
        # ç½‘ç»œæœç´¢ç›¸å…³
        self.last_user_question = ""  # è®°å½•æœ€åç”¨æˆ·é—®é¢˜
        self.search_in_progress = False  # æœç´¢è¿›è¡Œä¸­æ ‡å¿—
        
        # æœç´¢è§¦å‘è¯
        self.search_triggers = [
            "æˆ‘åšä¸åˆ°", "æˆ‘ä¸çŸ¥é“", "æˆ‘æ— æ³•", "æŠ±æ­‰ï¼Œæˆ‘ä¸èƒ½", 
            "æˆ‘æ²¡æœ‰ç›¸å…³ä¿¡æ¯", "æˆ‘æ— æ³•æä¾›", "æˆ‘ä¸ç¡®å®š", "æˆ‘æ²¡æœ‰è¿™æ–¹é¢çš„ä¿¡æ¯",
            "æˆ‘éœ€è¦æœç´¢", "è®©æˆ‘æœç´¢ä¸€ä¸‹", "æˆ‘å»æŸ¥ä¸€æŸ¥", "æˆ‘éœ€è¦æŸ¥æ‰¾"
        ]
        
        print("ğŸ¤ æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼ˆå«ç½‘ç»œæœç´¢ï¼‰")
    
    async def _configure_session(self):
        """é…ç½®ä¼šè¯"""
        config = get_voice_session_config()
        config["instructions"] = (
            "ä½ æ˜¯é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·çš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œå…·å¤‡ç½‘ç»œæœç´¢èƒ½åŠ›ã€‚"
            "è¯·ç”¨è‡ªç„¶ã€è¿è´¯çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å›ç­”è¦ç®€æ´æ˜äº†ï¼Œè¯­è°ƒäº²å’Œå‹å¥½ã€‚"
            "\né‡è¦åŠŸèƒ½è¯´æ˜ï¼š"
            "1. å½“é‡åˆ°ä½ æ— æ³•ç›´æ¥å›ç­”çš„é—®é¢˜ï¼ˆå¦‚æœ€æ–°ä¿¡æ¯ã€å®æ—¶æ•°æ®ã€ä¸“ä¸šçŸ¥è¯†ç­‰ï¼‰æ—¶ï¼Œ"
            "è¯·æ˜ç¡®å‘Šè¯‰ç”¨æˆ·ï¼š'è®©æˆ‘ä¸ºæ‚¨æœç´¢æœ€æ–°ä¿¡æ¯'ï¼Œç„¶åè¯´'æˆ‘éœ€è¦æœç´¢'ã€‚"
            "2. å½“ä½ è¯´å‡º'æˆ‘éœ€è¦æœç´¢'æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¯åŠ¨ç½‘ç»œæœç´¢åŠŸèƒ½ã€‚"
            "3. æœç´¢å®Œæˆåï¼Œä½ ä¼šæ”¶åˆ°æœç´¢ç»“æœï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯é‡æ–°å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            "\nç¤ºä¾‹å›ç­”æ¨¡å¼ï¼š"
            "- å¯¹äºå®æ—¶ä¿¡æ¯ï¼š'è®©æˆ‘ä¸ºæ‚¨æœç´¢æœ€æ–°ä¿¡æ¯ã€‚æˆ‘éœ€è¦æœç´¢ã€‚'"
            "- å¯¹äºä¸“ä¸šé—®é¢˜ï¼š'è¿™ä¸ªé—®é¢˜æ¯”è¾ƒä¸“ä¸šï¼Œè®©æˆ‘æœç´¢è¯¦ç»†èµ„æ–™ã€‚æˆ‘éœ€è¦æœç´¢ã€‚'"
            "- å¯¹äºä¸ç¡®å®šä¿¡æ¯ï¼š'æˆ‘ä¸å¤ªç¡®å®šè¿™ä¸ªä¿¡æ¯ï¼Œè®©æˆ‘æœç´¢ç¡®è®¤ä¸€ä¸‹ã€‚æˆ‘éœ€è¦æœç´¢ã€‚'"
        )
        await self.websocket.send(json.dumps({"type": "session.update", "session": config}))
        
    def detect_search_trigger(self, text):
        """æ£€æµ‹æ˜¯å¦éœ€è¦è§¦å‘æœç´¢"""
        if not HAS_WEBSEARCH or not text:
            return False
            
        text_lower = text.lower()
        for trigger in self.search_triggers:
            if trigger in text_lower:
                return True
        return False
    
    async def perform_web_search(self, question):
        """æ‰§è¡Œç½‘ç»œæœç´¢"""
        if not HAS_WEBSEARCH or not question.strip():
            return "æœç´¢åŠŸèƒ½ä¸å¯ç”¨æˆ–é—®é¢˜ä¸ºç©º"
            
        try:
            print(f"\nğŸ” æ­£åœ¨æœç´¢: {question}")
            
            # ä½¿ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½
            search_result = await web_search_and_browse(
                query=question,
                search_engine="duckduckgo", 
                num_results=3,
                max_browse=1,  # æµè§ˆç¬¬ä¸€ä¸ªç»“æœ
                max_length=3000  # é™åˆ¶å†…å®¹é•¿åº¦
            )
            
            print(f"âœ… æœç´¢å®Œæˆï¼Œç»“æœé•¿åº¦: {len(search_result)}å­—ç¬¦")
            return search_result
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return f"æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def synthesize_search_response(self, search_result):
        """åˆæˆæœç´¢ç»“æœå›ç­”"""
        if not search_result or "æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯" in search_result:
            return "æŠ±æ­‰ï¼Œæœç´¢æ—¶é‡åˆ°äº†é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
        # ç®€åŒ–æœç´¢ç»“æœï¼Œæå–å…³é”®ä¿¡æ¯
        lines = search_result.split('\n')
        useful_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('ğŸ”') and not line.startswith('ğŸ“Œ') and not line.startswith('ğŸ”—'):
                useful_lines.append(line)
                if len(useful_lines) >= 8:  # é™åˆ¶è¡Œæ•°
                    break
        
        summary = ' '.join(useful_lines[:5])  # å–å‰5è¡Œä½œä¸ºæ‘˜è¦
        if len(summary) > 800:  # é™åˆ¶é•¿åº¦
            summary = summary[:800] + "..."
            
        return f"æ ¹æ®æœç´¢ç»“æœï¼Œ{summary}"
    
    async def _handle_search_trigger(self):
        """å¤„ç†æœç´¢è§¦å‘"""
        try:
            if not self.last_user_question.strip():
                print("âš ï¸ æ²¡æœ‰è®°å½•åˆ°ç”¨æˆ·é—®é¢˜ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")
                self.search_in_progress = False
                return
            
            print(f"\nğŸ” AIè§¦å‘æœç´¢åŠŸèƒ½")
            
            # æ‰§è¡Œæœç´¢
            search_result = await self.perform_web_search(self.last_user_question)
            
            if search_result and "æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯" not in search_result:
                # åˆæˆæœç´¢ç»“æœå›ç­”
                enhanced_response = self.synthesize_search_response(search_result)
                
                # é€šè¿‡websocketå‘é€æ–°çš„å›ç­”
                await self._send_search_response(enhanced_response)
            else:
                print("âŒ æœç´¢å¤±è´¥ï¼Œæ— æ³•æä¾›å¢å¼ºå›ç­”")
                
        except Exception as e:
            print(f"âŒ æœç´¢å¤„ç†é”™è¯¯: {e}")
        finally:
            self.search_in_progress = False
    
    async def _send_search_response(self, response_text):
        """å‘é€æœç´¢ç»“æœå›ç­”"""
        try:
            print(f"\nğŸ” åŸºäºæœç´¢ç»“æœçš„å›ç­”:")
            print(f"ğŸ’¬ AI: {response_text}")
            
            # å‘é€ä¼šè¯é¡¹ç›®ä»¥åŒ…å«æœç´¢ç»“æœ
            message = {
                "type": "conversation.item.create",
                "item": {
                    "type": "message",
                    "role": "assistant",
                    "content": [
                        {
                            "type": "text",
                            "text": response_text
                        }
                    ]
                }
            }
            await self.websocket.send(json.dumps(message))
            
            # è¯·æ±‚å“åº”
            response_request = {"type": "response.create"}
            await self.websocket.send(json.dumps(response_request))
            
        except Exception as e:
            print(f"âŒ å‘é€æœç´¢å›ç­”å¤±è´¥: {e}")

    def _recording_worker(self):
        """å½•éŸ³å·¥ä½œçº¿ç¨‹ - æç®€ç‰ˆ"""
        print("ğŸ¤ å½•éŸ³çº¿ç¨‹å¯åŠ¨")
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                audio_data = self.input_stream.read(1024, exception_on_overflow=False)
                
                # ç®€å•çš„éŸ³é‡æ£€æµ‹
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                if len(audio_array) > 0:
                    volume = np.sqrt(np.mean(audio_array.astype(np.float64)**2))
                    
                    # æ£€æµ‹ç”¨æˆ·è¯´è¯
                    if volume > 20:  # ç®€å•é˜ˆå€¼
                        if not self.user_speaking:
                            self.user_speaking = True
                            if not self.last_user_input_shown:
                                print(f"\nğŸ¤ [æ­£åœ¨å¬å–æ‚¨çš„é—®é¢˜...]", flush=True)
                        
                        # å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œåˆ™æ‰“æ–­
                        if self.is_ai_speaking:
                            self._interrupt_ai()
                    
                    # å‘é€éŸ³é¢‘åˆ°å¤„ç†é˜Ÿåˆ—
                    if not self.audio_queue.full():
                        self.audio_queue.put(audio_data)
                
                time.sleep(0.01)
                
            except Exception as e:
                if self.is_recording:
                    print(f"\nâŒ å½•éŸ³é”™è¯¯: {e}")
                break
        
        print(f"\nğŸ›‘ å½•éŸ³çº¿ç¨‹ç»“æŸ")
    
    def _interrupt_ai(self):
        """æ‰“æ–­AI"""
        if self.is_ai_speaking:
            self.interrupt_detected = True
            self.is_ai_speaking = False
            
            # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
            while not self.audio_buffer.empty():
                try:
                    self.audio_buffer.get_nowait()
                except:
                    break
            
            # æ˜¾ç¤ºä¸å®Œæ•´å›ç­”
            if self.current_ai_response.strip():
                print(f"\nğŸ’¬ AI: {self.current_ai_response.strip()} [è¢«æ‰“æ–­]")
            else:
                print(f"\nâš¡ [AIè¢«æ‰“æ–­]")
            
            # é‡ç½®å›ç­”ç´¯ç§¯
            self.current_ai_response = ""
    
    def _processing_worker(self):
        """å¤„ç†å·¥ä½œçº¿ç¨‹"""
        print("ğŸ”„ å¤„ç†çº¿ç¨‹å¯åŠ¨")
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            loop.run_until_complete(self._async_processing())
        finally:
            loop.close()
    
    async def _async_processing(self):
        """å¼‚æ­¥å¤„ç†"""
        while self.is_recording and not self.stop_event.is_set():
            try:
                # å‘é€å–æ¶ˆä¿¡å·ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if self.interrupt_detected:
                    await self._send_cancel()
                    self.interrupt_detected = False
                
                # å‘é€éŸ³é¢‘
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get_nowait()
                    await self._send_audio_chunk(audio_data)
                
                # å¤„ç†å“åº”
                await self._handle_responses()
                await asyncio.sleep(0.02)
                
            except Exception as e:
                if "websocket" not in str(e).lower():
                    print(f"\nâŒ å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.1)
    
    async def _send_cancel(self):
        """å‘é€å–æ¶ˆä¿¡å·"""
        try:
            cancel_msg = {"type": "response.cancel"}
            await self.websocket.send(json.dumps(cancel_msg))
            print("\rğŸš« [å–æ¶ˆä¿¡å·å·²å‘é€]", end="", flush=True)
        except:
            pass
    
    async def _handle_responses(self):
        """å¤„ç†AIå“åº”"""
        try:
            message = await asyncio.wait_for(self.websocket.recv(), timeout=0.01)
            data = json.loads(message)
            response_type = data.get("type", "")
            
            if response_type == "response.audio.delta":
                # AIéŸ³é¢‘å›ç­”
                audio_base64 = data.get("delta", "")
                if audio_base64 and not self.interrupt_detected:
                    self.audio_buffer.put(audio_base64)
                    if not self.is_ai_speaking:
                        self.is_ai_speaking = True
                        print("\nğŸ¤– [AIæ­£åœ¨å›ç­”...]")
            
            elif response_type == "response.audio_transcript.delta":
                # AIæ–‡æœ¬å›ç­”ï¼ˆç´¯ç§¯æ˜¾ç¤ºï¼‰
                transcript = data.get("delta", "")
                if transcript.strip() and not self.interrupt_detected:
                    self.current_ai_response += transcript
            
            elif response_type == "response.audio_transcript.done":
                # AIæ–‡æœ¬å›ç­”å®Œæˆï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹
                if not self.interrupt_detected and self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()}")
                    
                    # æ£€æµ‹æ˜¯å¦éœ€è¦è§¦å‘æœç´¢
                    if self.detect_search_trigger(self.current_ai_response) and not self.search_in_progress:
                        self.search_in_progress = True
                        asyncio.create_task(self._handle_search_trigger())
                    
                    self.current_ai_response = ""
            
            elif response_type == "response.done":
                # AIå›ç­”å®Œæˆ
                self.is_ai_speaking = False
                self.last_user_input_shown = False  # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹æ¬¡ç”¨æˆ·è¾“å…¥
                if not self.interrupt_detected:
                    print("âœ… [AIå›ç­”å®Œæˆ]\n")
            
            elif response_type == "response.cancelled":
                # AIå›ç­”è¢«å–æ¶ˆ
                self.is_ai_speaking = False
                if self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()} [å·²å–æ¶ˆ]")
                else:
                    print("ğŸš« [AIå›ç­”å·²å–æ¶ˆ]")
                self.current_ai_response = ""
            
            elif response_type == "conversation.item.input_audio_transcription.completed":
                # ç”¨æˆ·è¯­éŸ³è¯†åˆ«å®Œæˆ
                transcript = data.get("transcript", "")
                if transcript.strip():
                    self.user_speaking = False
                    self.last_user_input_shown = True
                    self.last_user_question = transcript  # è®°å½•ç”¨æˆ·é—®é¢˜ç”¨äºæœç´¢
                    print(f"ğŸ‘¤ æ‚¨è¯´: {transcript}")
            
            elif response_type == "error":
                error_msg = data.get("error", {}).get("message", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ é”™è¯¯: {error_msg}")
        
        except asyncio.TimeoutError:
            # æ­£å¸¸æƒ…å†µï¼Œæ²¡æœ‰æ–°æ¶ˆæ¯
            pass
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        except Exception as e:
            if "websocket" not in str(e).lower():
                print(f"âŒ å“åº”å¤„ç†é”™è¯¯: {e}")
    
    def _audio_playback_worker(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
        print("ğŸ”Š éŸ³é¢‘æ’­æ”¾çº¿ç¨‹å¯åŠ¨")
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                if not self.audio_buffer.empty():
                    audio_base64 = self.audio_buffer.get(timeout=0.1)
                    if not self.interrupt_detected:
                        self._play_audio(audio_base64)
                else:
                    time.sleep(0.01)
            except queue.Empty:
                time.sleep(0.01)
            except Exception as e:
                print(f"âŒ æ’­æ”¾é”™è¯¯: {e}")
    
    def _play_audio(self, audio_base64):
        """æ’­æ”¾éŸ³é¢‘"""
        try:
            if not HAS_PYAUDIO or self.interrupt_detected:
                return
            
            audio_data = base64.b64decode(audio_base64)
            
            if not self.output_stream:
                self.output_stream = self.pyaudio_instance.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=16000,
                    output=True,
                    frames_per_buffer=1024
                )
            
            # æ’­æ”¾éŸ³é¢‘
            if audio_data:
                self.output_stream.write(audio_data, exception_on_underflow=False)
        
        except Exception as e:
            if not self.interrupt_detected:
                print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")

async def run_simple_voice_assistant():
    """è¿è¡Œæç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹"""
    print("ğŸ« é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ - æç®€ç‰ˆ")
    print("ğŸ“ HKUST-GZ Intelligent Voice Assistant - Simple Edition")
    print("=" * 60)
    
    setup_api_keys()
    api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("QWEN_API_KEY")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return
    
    assistant = SimpleVoiceAssistant(api_key)
    
    try:
        print("ğŸ”— æ­£åœ¨è¿æ¥åƒé—®Omni API...")
        await assistant.connect()
        
        result = assistant.start_recording()
        if not result["success"]:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {result['error']}")
            return
        
        print("\nâœ… æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("\nğŸ¤ æ ¸å¿ƒåŠŸèƒ½:")
        print("   â€¢ å®æ—¶è¯­éŸ³å¯¹è¯")
        print("   â€¢ è‡ªåŠ¨éŸ³é‡æ£€æµ‹æ‰“æ–­")
        print("   â€¢ å®æ—¶AIå›ç­”å­—å¹•")
        print("   â€¢ æŒ‰ Ctrl+C é€€å‡º")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ ç›´æ¥è¯´è¯æé—®")
        print("   â€¢ å¼€å§‹è¯´è¯æ—¶ä¼šè‡ªåŠ¨æ‰“æ–­AI")
        print("   â€¢ ç­‰å¾…AIå›ç­”å®Œæˆåç»§ç»­å¯¹è¯")
        print("=" * 60)
        print("\nğŸ¤ å¼€å§‹å¯¹è¯å§...")
        
        # ä¸»å¾ªç¯
        while True:
            await asyncio.sleep(1)
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            if not assistant.is_recording:
                print("\nâš ï¸ æ£€æµ‹åˆ°å½•éŸ³ç³»ç»Ÿå·²åœæ­¢")
                break
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸»åŠ¨é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        print("\nğŸ§¹ æ­£åœ¨å…³é—­è¯­éŸ³åŠ©æ‰‹...")
        await assistant.disconnect()
        print("âœ… è¯­éŸ³åŠ©æ‰‹å·²å®‰å…¨å…³é—­")
        print("ğŸ“ æ„Ÿè°¢ä½¿ç”¨HKUST-GZæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼")

if __name__ == "__main__":
    asyncio.run(run_simple_voice_assistant()) 