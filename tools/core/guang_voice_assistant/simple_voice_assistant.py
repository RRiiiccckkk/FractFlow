#!/usr/bin/env python3
"""
Simple Voice Assistant for HKUST-GZ
Author: FractFlow Team
Brief: Simplified voice assistant without web search functionality
"""

import asyncio
import os
import sys
import json
import threading
import queue
import time
import numpy as np
import base64

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False
    pass  # PyAudioæœªå®‰è£…è­¦å‘Šï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰

from tools.core.qwen_realtime_voice.qwen_realtime_voice_mcp import QwenRealtimeVoiceClient
from .voice_config import setup_api_keys, get_voice_session_config

class SimpleVoiceAssistant(QwenRealtimeVoiceClient):
    """æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½"""
    
    def __init__(self, api_key=None):
        super().__init__(api_key)
        
        # æ ¸å¿ƒçŠ¶æ€
        self.is_ai_speaking = False
        self.interrupt_detected = False
        self.user_speaking = False
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = queue.Queue(maxsize=50)
        
        # æ–‡æœ¬ç´¯ç§¯
        self.current_ai_response = ""
        self.last_user_input_shown = False
        
        # åˆå§‹åŒ–å®Œæˆï¼ˆç§»é™¤printä»¥é¿å…MCPé€šä¿¡å¹²æ‰°ï¼‰
    
    async def _configure_session(self):
        """é…ç½®ä¼šè¯"""
        config = get_voice_session_config()
        # ç§»é™¤ç½‘ç»œæœç´¢ç›¸å…³çš„æŒ‡ä»¤
        config["instructions"] = (
            "ä½ æ˜¯é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·çš„æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€‚"
            "è¯·ç”¨è‡ªç„¶ã€è¿è´¯çš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å›ç­”è¦ç®€æ´æ˜äº†ï¼Œè¯­è°ƒäº²å’Œå‹å¥½ã€‚"
        )
        await self.websocket.send(json.dumps({"type": "session.update", "session": config}))

    def _recording_worker(self):
        """å½•éŸ³å·¥ä½œçº¿ç¨‹ - æç®€ç‰ˆ"""
        # å½•éŸ³çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                audio_data = self.input_stream.read(1024, exception_on_overflow=False)
                
                # ç®€å•çš„éŸ³é‡æ£€æµ‹
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                if len(audio_array) > 0:
                    volume = np.sqrt(np.mean(audio_array.astype(np.float64)**2))
                    
                    # æ£€æµ‹ç”¨æˆ·è¯´è¯
                    if volume > 20:  # ç®€å•é˜ˆå€¼
                        if not self.user_speaking:
                            self.user_speaking = True
                            if not self.last_user_input_shown:
                                print(f"\nğŸ¤ [æ­£åœ¨å¬å–æ‚¨çš„é—®é¢˜...]", flush=True)
                        
                        # å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œåˆ™æ‰“æ–­
                        if self.is_ai_speaking:
                            self._interrupt_ai()
                    
                    # å‘é€éŸ³é¢‘åˆ°å¤„ç†é˜Ÿåˆ—
                    if not self.audio_queue.full():
                        self.audio_queue.put(audio_data)
                
                time.sleep(0.01)
                
            except Exception as e:
                if self.is_recording:
                    print(f"\nâŒ å½•éŸ³é”™è¯¯: {e}")
                break
        
        print(f"\nğŸ›‘ å½•éŸ³çº¿ç¨‹ç»“æŸ")
    
    def _interrupt_ai(self):
        """æ‰“æ–­AI"""
        if self.is_ai_speaking:
            self.interrupt_detected = True
            self.is_ai_speaking = False
            
            # æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
            while not self.audio_buffer.empty():
                try:
                    self.audio_buffer.get_nowait()
                except:
                    break
            
            # æ˜¾ç¤ºä¸å®Œæ•´å›ç­”
            if self.current_ai_response.strip():
                print(f"\nğŸ’¬ AI: {self.current_ai_response.strip()} [è¢«æ‰“æ–­]")
            else:
                print(f"\nâš¡ [AIè¢«æ‰“æ–­]")
            
            # é‡ç½®å›ç­”ç´¯ç§¯
            self.current_ai_response = ""
    
    def _processing_worker(self):
        """å¤„ç†å·¥ä½œçº¿ç¨‹"""
        # å¤„ç†çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            loop.run_until_complete(self._async_processing())
        finally:
            loop.close()
    
    async def _async_processing(self):
        """å¼‚æ­¥å¤„ç†"""
        while self.is_recording and not self.stop_event.is_set():
            try:
                # å‘é€å–æ¶ˆä¿¡å·ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if self.interrupt_detected:
                    await self._send_cancel()
                    self.interrupt_detected = False
                
                # å‘é€éŸ³é¢‘
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get_nowait()
                    await self._send_audio_chunk(audio_data)
                
                # å¤„ç†å“åº”
                await self._handle_responses()
                await asyncio.sleep(0.02)
                
            except Exception as e:
                if "websocket" not in str(e).lower():
                    print(f"\nâŒ å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.1)
    
    async def _send_cancel(self):
        """å‘é€å–æ¶ˆä¿¡å·"""
        try:
            cancel_msg = {"type": "response.cancel"}
            await self.websocket.send(json.dumps(cancel_msg))
            print("\rğŸš« [å–æ¶ˆä¿¡å·å·²å‘é€]", end="", flush=True)
        except:
            pass
    
    async def _handle_responses(self):
        """å¤„ç†AIå“åº”"""
        try:
            message = await asyncio.wait_for(self.websocket.recv(), timeout=0.01)
            data = json.loads(message)
            response_type = data.get("type", "")
            
            if response_type == "response.audio.delta":
                # AIéŸ³é¢‘å›ç­”
                audio_base64 = data.get("delta", "")
                if audio_base64 and not self.interrupt_detected:
                    self.audio_buffer.put(audio_base64)
                    if not self.is_ai_speaking:
                        self.is_ai_speaking = True
                        print("\nğŸ¤– [AIæ­£åœ¨å›ç­”...]")
            
            elif response_type == "response.audio_transcript.delta":
                # AIæ–‡æœ¬å›ç­”ï¼ˆç´¯ç§¯æ˜¾ç¤ºï¼‰
                transcript = data.get("delta", "")
                if transcript.strip() and not self.interrupt_detected:
                    self.current_ai_response += transcript
            
            elif response_type == "response.audio_transcript.done":
                # AIæ–‡æœ¬å›ç­”å®Œæˆï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹
                if not self.interrupt_detected and self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()}")
                    self.current_ai_response = ""
            
            elif response_type == "response.done":
                # AIå›ç­”å®Œæˆ
                self.is_ai_speaking = False
                self.last_user_input_shown = False  # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹æ¬¡ç”¨æˆ·è¾“å…¥
                if not self.interrupt_detected:
                    print("âœ… [AIå›ç­”å®Œæˆ]\n")
            
            elif response_type == "response.cancelled":
                # AIå›ç­”è¢«å–æ¶ˆ
                self.is_ai_speaking = False
                if self.current_ai_response.strip():
                    print(f"ğŸ’¬ AI: {self.current_ai_response.strip()} [å·²å–æ¶ˆ]")
                else:
                    print("ğŸš« [AIå›ç­”å·²å–æ¶ˆ]")
                self.current_ai_response = ""
            
            elif response_type == "conversation.item.input_audio_transcription.completed":
                # ç”¨æˆ·è¯­éŸ³è¯†åˆ«å®Œæˆ
                transcript = data.get("transcript", "")
                if transcript.strip():
                    self.user_speaking = False
                    self.last_user_input_shown = True
                    print(f"ğŸ‘¤ æ‚¨è¯´: {transcript}")
            
            elif response_type == "error":
                error_msg = data.get("error", {}).get("message", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ é”™è¯¯: {error_msg}")
        
        except asyncio.TimeoutError:
            # æ­£å¸¸æƒ…å†µï¼Œæ²¡æœ‰æ–°æ¶ˆæ¯
            pass
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {e}")
        except Exception as e:
            if "websocket" not in str(e).lower():
                print(f"âŒ å“åº”å¤„ç†é”™è¯¯: {e}")
    
    def _audio_playback_worker(self):
        """éŸ³é¢‘æ’­æ”¾çº¿ç¨‹"""
        # éŸ³é¢‘æ’­æ”¾çº¿ç¨‹å¯åŠ¨ï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                if not self.audio_buffer.empty():
                    audio_base64 = self.audio_buffer.get(timeout=0.1)
                    if not self.interrupt_detected:
                        self._play_audio(audio_base64)
                else:
                    time.sleep(0.01)
            except queue.Empty:
                time.sleep(0.01)
            except Exception as e:
                print(f"âŒ æ’­æ”¾é”™è¯¯: {e}")
    
    def _play_audio(self, audio_base64):
        """æ’­æ”¾éŸ³é¢‘"""
        try:
            if not HAS_PYAUDIO or self.interrupt_detected:
                return
            
            audio_data = base64.b64decode(audio_base64)
            
            if not self.output_stream:
                self.output_stream = self.pyaudio_instance.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=16000,
                    output=True,
                    frames_per_buffer=1024
                )
            
            # æ’­æ”¾éŸ³é¢‘
            if audio_data:
                self.output_stream.write(audio_data, exception_on_underflow=False)
        
        except Exception as e:
            if not self.interrupt_detected:
                print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")

async def run_simple_voice_assistant():
    """è¿è¡Œæç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹"""
    print("ğŸ« é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¹¿å·æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ - æç®€ç‰ˆ")
    print("ğŸ“ HKUST-GZ Intelligent Voice Assistant - Simple Edition")
    print("=" * 60)
    
    setup_api_keys()
    api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("QWEN_API_KEY")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return
    
    assistant = SimpleVoiceAssistant(api_key)
    
    try:
        # æ­£åœ¨è¿æ¥åƒé—®Omni APIï¼ˆç§»é™¤printé¿å…MCPå¹²æ‰°ï¼‰
        await assistant.connect()
        
        result = assistant.start_recording()
        if not result["success"]:
            print(f"âŒ å¯åŠ¨å¤±è´¥: {result['error']}")
            return
        
        print("\nâœ… æç®€ç‰ˆè¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("\nğŸ¤ æ ¸å¿ƒåŠŸèƒ½:")
        print("   â€¢ å®æ—¶è¯­éŸ³å¯¹è¯")
        print("   â€¢ è‡ªåŠ¨éŸ³é‡æ£€æµ‹æ‰“æ–­")
        print("   â€¢ å®æ—¶AIå›ç­”å­—å¹•")
        print("   â€¢ æŒ‰ Ctrl+C é€€å‡º")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ ç›´æ¥è¯´è¯æé—®")
        print("   â€¢ å¼€å§‹è¯´è¯æ—¶ä¼šè‡ªåŠ¨æ‰“æ–­AI")
        print("   â€¢ ç­‰å¾…AIå›ç­”å®Œæˆåç»§ç»­å¯¹è¯")
        print("=" * 60)
        print("\nğŸ¤ å¼€å§‹å¯¹è¯å§...")
        
        # ä¸»å¾ªç¯
        while True:
            await asyncio.sleep(1)
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            if not assistant.is_recording:
                print("\nâš ï¸ æ£€æµ‹åˆ°å½•éŸ³ç³»ç»Ÿå·²åœæ­¢")
                break
                
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸»åŠ¨é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        print("\nğŸ§¹ æ­£åœ¨å…³é—­è¯­éŸ³åŠ©æ‰‹...")
        await assistant.disconnect()
        print("âœ… è¯­éŸ³åŠ©æ‰‹å·²å®‰å…¨å…³é—­")
        print("ğŸ“ æ„Ÿè°¢ä½¿ç”¨HKUST-GZæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼")

if __name__ == "__main__":
    asyncio.run(run_simple_voice_assistant()) 