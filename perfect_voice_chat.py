#!/usr/bin/env python3
"""
å®Œç¾ç‰ˆè¯­éŸ³äº¤äº’ç¨‹åº
ä¿®å¤äº†æ‰€æœ‰å‘ç°çš„é—®é¢˜ï¼Œæä¾›æœ€ä½³çš„è¯­éŸ³äº¤äº’ä½“éªŒ
"""

import asyncio
import os
import sys
import json
import threading
import queue
import time
import numpy as np

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False

from tools.core.qwen_realtime_voice.qwen_realtime_voice_mcp import QwenRealtimeVoiceClient

class PerfectVoiceClient(QwenRealtimeVoiceClient):
    """å®Œç¾ç‰ˆè¯­éŸ³å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key=None):
        super().__init__(api_key)
        self.debug_mode = True
        
    async def _configure_session(self):
        """ä¼˜åŒ–çš„ä¼šè¯é…ç½®"""
        config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡è‡ªç„¶åœ°å›ç­”é—®é¢˜ã€‚ä¿æŒå›å¤ç®€æ´æ˜äº†ã€‚æ”¯æŒè¢«ç”¨æˆ·éšæ—¶æ‰“æ–­ã€‚",
                "voice": "Chelsie",  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„è¯­éŸ³åç§°
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.15,  # ä¼˜åŒ–ï¼šå¹³è¡¡æ•æ„Ÿåº¦
                    "prefix_padding_ms": 150,  # ä¼˜åŒ–ï¼šé€‚ä¸­çš„å‰ç¼€
                    "silence_duration_ms": 400  # ä¼˜åŒ–ï¼šé€‚ä¸­çš„é™éŸ³æ—¶é—´
                },
                "temperature": 0.7,
                "max_response_output_tokens": 2048
            }
        }
        
        await self.websocket.send(json.dumps(config))
        print("âš™ï¸ ä¼šè¯é…ç½®å®Œæˆï¼ˆä½¿ç”¨å®Œç¾ä¼˜åŒ–è®¾ç½®ï¼‰")
    
    def select_best_microphone(self):
        """é€‰æ‹©æœ€ä½³éº¦å…‹é£è®¾å¤‡"""
        if not HAS_PYAUDIO:
            return None
        
        p = pyaudio.PyAudio()
        device_count = p.get_device_count()
        
        # ä¼˜å…ˆé€‰æ‹©MacBookå†…ç½®éº¦å…‹é£
        for i in range(device_count):
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                if "MacBook" in info['name'] and "Microphone" in info['name']:
                    print(f"ğŸ¤ è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡: {info['name']}")
                    p.terminate()
                    return i
        
        # å¦‚æœæ²¡æœ‰å†…ç½®éº¦å…‹é£ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨è®¾å¤‡
        for i in range(device_count):
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0 and "OPPO" not in info['name']:  # é¿å…OPPOå…¼å®¹æ€§é—®é¢˜
                print(f"ğŸ¤ é€‰æ‹©å¤‡ç”¨è®¾å¤‡: {info['name']}")
                p.terminate()
                return i
        
        p.terminate()
        return None
    
    def start_recording(self):
        """å¢å¼ºçš„å½•éŸ³å¯åŠ¨"""
        if not HAS_PYAUDIO:
            return {"success": False, "error": "PyAudioä¸å¯ç”¨"}
        
        try:
            # åˆå§‹åŒ–PyAudio
            if not self.pyaudio_instance:
                self.pyaudio_instance = pyaudio.PyAudio()
            
            # é€‰æ‹©æœ€ä½³éº¦å…‹é£
            device_id = self.select_best_microphone()
            if device_id is None:
                return {"success": False, "error": "æœªæ‰¾åˆ°åˆé€‚çš„éº¦å…‹é£è®¾å¤‡"}
            
            # åˆ›å»ºè¾“å…¥æµ
            self.input_stream = self.pyaudio_instance.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,  # æ ‡å‡†é‡‡æ ·ç‡
                input=True,
                input_device_index=device_id,
                frames_per_buffer=1024
            )
            
            # åˆ›å»ºè¾“å‡ºæµï¼ˆç”¨äºæ’­æ”¾AIè¯­éŸ³ï¼‰
            self.output_stream = self.pyaudio_instance.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                output=True
            )
            
            self.is_recording = True
            self.stop_event.clear()
            self.stop_playback_event.clear()
            
            # å¯åŠ¨çº¿ç¨‹
            self.recording_thread = threading.Thread(target=self._enhanced_recording_worker)
            self.recording_thread.start()
            
            self.processing_thread = threading.Thread(target=self._processing_worker)
            self.processing_thread.start()
            
            self.audio_playback_thread = threading.Thread(target=self._audio_playback_worker)
            self.audio_playback_thread.start()
            
            print("ğŸ¤ å®Œç¾å½•éŸ³ç³»ç»Ÿå·²å¯åŠ¨")
            return {"success": True, "message": "å½•éŸ³å¼€å§‹"}
            
        except Exception as e:
            return {"success": False, "error": f"å½•éŸ³å¯åŠ¨å¤±è´¥: {e}"}
    
    def _enhanced_recording_worker(self):
        """å¢å¼ºçš„å½•éŸ³å·¥ä½œçº¿ç¨‹"""
        print("ğŸµ å®Œç¾å½•éŸ³çº¿ç¨‹å¯åŠ¨")
        
        chunk_count = 0
        silent_chunks = 0
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data = self.input_stream.read(1024, exception_on_overflow=False)
                
                # ç®€å•çš„éŸ³é¢‘çº§åˆ«æ£€æµ‹
                if self.debug_mode and chunk_count % 50 == 0:
                    audio_array = np.frombuffer(audio_data, dtype=np.int16)
                    if len(audio_array) > 0:
                        volume = np.sqrt(np.mean(audio_array.astype(np.float64)**2))
                        if not np.isnan(volume):
                            if volume > 200:
                                print(f"\rğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ (éŸ³é‡: {volume:.0f})  ", end="", flush=True)
                                silent_chunks = 0
                            else:
                                silent_chunks += 1
                                if silent_chunks > 100:  # 5ç§’é™éŸ³åæ˜¾ç¤ºç­‰å¾…çŠ¶æ€
                                    print(f"\rğŸ¤ ç­‰å¾…è¯­éŸ³è¾“å…¥...                    ", end="", flush=True)
                                    silent_chunks = 0
                
                # æ”¾å…¥é˜Ÿåˆ—
                if not self.audio_queue.full():
                    self.audio_queue.put(audio_data)
                
                chunk_count += 1
                time.sleep(0.01)
                
            except Exception as e:
                if self.is_recording:
                    print(f"\nâŒ å½•éŸ³é”™è¯¯: {e}")
                break
                
        print(f"\nğŸ›‘ å½•éŸ³çº¿ç¨‹ç»“æŸ")
    
    async def _handle_responses(self):
        """å¢å¼ºçš„å“åº”å¤„ç†"""
        try:
            message = await asyncio.wait_for(self.websocket.recv(), timeout=0.01)
            response_data = json.loads(message)
            
            response_type = response_data.get("type", "")
            
            if response_type == "input_audio_buffer.speech_started":
                print(f"\nğŸ¤ [æ£€æµ‹åˆ°è¯­éŸ³] å¼€å§‹è¯†åˆ«...")
                if self.is_ai_speaking:
                    await self._interrupt_ai_response()
                    
            elif response_type == "input_audio_buffer.speech_stopped":
                print(f"ğŸ”‡ [è¯­éŸ³ç»“æŸ] æ­£åœ¨å¤„ç†...")
                self.interrupt_detected = False
                
            elif response_type == "conversation.item.input_audio_transcription.completed":
                # è·å–è½¬å½•æ–‡æœ¬
                item = response_data.get("item", {})
                content = item.get("content", [])
                if content and len(content) > 0:
                    transcript = content[0].get("transcript", "")
                    if transcript:
                        print(f"ğŸ‘¤ æ‚¨è¯´: {transcript}")
                
            elif response_type == "response.created":
                print(f"ğŸ¤– AIæ­£åœ¨æ€è€ƒ...")
                
            elif response_type == "response.audio_transcript.delta":
                transcript = response_data.get("delta", "")
                if transcript.strip():
                    print(f"ğŸ¤– AI: {transcript}", end="", flush=True)
                    
            elif response_type == "response.audio_transcript.done":
                print()  # æ¢è¡Œ
                
            elif response_type == "response.audio.delta":
                audio_base64 = response_data.get("delta", "")
                if audio_base64 and not self.interrupt_detected:
                    self.audio_buffer.put(audio_base64)
                    self.is_ai_speaking = True
                    
            elif response_type == "response.done":
                print("âœ… [å¯¹è¯å®Œæˆ] è¯·ç»§ç»­è¯´è¯...")
                self.is_ai_speaking = False
                
            elif response_type == "error":
                error_info = response_data.get("error", {})
                print(f"\nâŒ é”™è¯¯: {error_info.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
        except asyncio.TimeoutError:
            pass
        except Exception as e:
            if "websocket" not in str(e).lower():
                print(f"\nâŒ å“åº”å¤„ç†é”™è¯¯: {e}")

async def run_perfect_voice_chat():
    """è¿è¡Œå®Œç¾ç‰ˆè¯­éŸ³èŠå¤©"""
    print("ğŸ™ï¸ åƒé—®Omniå®Œç¾è¯­éŸ³äº¤äº’ç³»ç»Ÿ")
    print("="*60)
    
    client = PerfectVoiceClient()
    
    try:
        # è¿æ¥API
        print("ğŸ”— æ­£åœ¨è¿æ¥åƒé—®Omni API...")
        connect_result = await client.connect()
        if not connect_result["success"]:
            print(f"âŒ è¿æ¥å¤±è´¥: {connect_result['error']}")
            return
        
        print(f"âœ… è¿æ¥æˆåŠŸï¼ä¼šè¯ID: {connect_result['session_id']}")
        
        # å¯åŠ¨å½•éŸ³
        print("ğŸ¤ æ­£åœ¨å¯åŠ¨å®Œç¾å½•éŸ³ç³»ç»Ÿ...")
        record_result = client.start_recording()
        if not record_result["success"]:
            print(f"âŒ å½•éŸ³å¯åŠ¨å¤±è´¥: {record_result['error']}")
            return
        
        print("\n" + "ğŸ‰" * 20)
        print("âœ… å®Œç¾è¯­éŸ³äº¤äº’ç³»ç»Ÿå·²å¯åŠ¨ï¼")
        print("\nğŸ’¡ ç³»ç»Ÿç‰¹æ€§:")
        print("   ğŸ¤ è‡ªåŠ¨é€‰æ‹©æœ€ä½³éº¦å…‹é£")
        print("   ğŸ”Š é«˜è´¨é‡è¯­éŸ³æ’­æ”¾")
        print("   âš¡ ä¼˜åŒ–çš„è¯­éŸ³æ£€æµ‹")
        print("   ğŸ¤– å®æ—¶å¯¹è¯äº¤äº’")
        print("   ğŸ“ è¯­éŸ³è½¬å½•æ˜¾ç¤º")
        print("\nğŸ—£ï¸ ä½¿ç”¨æŒ‡å—:")
        print("   â€¢ ç›´æ¥å¯¹ç€éº¦å…‹é£è¯´è¯")
        print("   â€¢ ç­‰å¾…AIè¯­éŸ³å›å¤")
        print("   â€¢ å¯ä»¥éšæ—¶æ‰“æ–­AIè¯´è¯")
        print("   â€¢ æŒ‰ Ctrl+C é€€å‡º")
        print("ğŸ‰" * 20)
        print("\nğŸ¤ ç³»ç»Ÿå°±ç»ªï¼Œè¯·å¼€å§‹å¯¹è¯...")
        
        # ä¿æŒè¿è¡Œ
        while True:
            await asyncio.sleep(1)
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ç»“æŸå¯¹è¯")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        print("\nğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        client.stop_recording()
        await client.disconnect()
        print("âœ… å®Œç¾è¯­éŸ³äº¤äº’ç³»ç»Ÿå·²å…³é—­")
        print("ğŸ‘‹ å†è§ï¼")

if __name__ == "__main__":
    asyncio.run(run_perfect_voice_chat()) 