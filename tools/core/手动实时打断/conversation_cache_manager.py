#!/usr/bin/env python3
"""
å¯¹è¯ç¼“å­˜ç®¡ç†å™¨
æ”¯æŒå¤–éƒ¨æ–‡ä»¶å­˜å‚¨ã€ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¯¹è¯è¿ç»­æ€§
"""

import json
import os
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import hashlib
import threading
from pathlib import Path

class ConversationCacheManager:
    """å¯¹è¯ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = "conversation_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # å½“å‰ä¼šè¯ä¿¡æ¯
        self.session_id = self._generate_session_id()
        self.session_file = self.cache_dir / f"session_{self.session_id}.json"
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        self.current_turn = 0
        
        # é…ç½®å‚æ•°
        self.max_context_length = 4000  # æœ€å¤§ä¸Šä¸‹æ–‡å­—ç¬¦æ•°
        self.max_turns_in_memory = 20   # å†…å­˜ä¸­ä¿ç•™çš„æœ€å¤§è½®æ•°
        self.auto_save_interval = 30    # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰
        
        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.Lock()
        
        # å¯åŠ¨æ—¶åŠ è½½å†å²ä¼šè¯
        self._load_recent_session()
        
        print(f"ğŸ“ å¯¹è¯ç¼“å­˜ç®¡ç†å™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_dir}")
        print(f"ğŸ†” ä¼šè¯ID: {self.session_id}")
        print(f"ğŸ“š å†å²å¯¹è¯: {len(self.conversation_history)} è½®")
    
    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        random_hash = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]
        return f"{timestamp}_{random_hash}"
    
    def _load_recent_session(self) -> None:
        """åŠ è½½æœ€è¿‘çš„ä¼šè¯å†å²"""
        try:
            # æŸ¥æ‰¾æœ€è¿‘çš„ä¼šè¯æ–‡ä»¶
            session_files = list(self.cache_dir.glob("session_*.json"))
            if not session_files:
                print("ğŸ“„ æœªæ‰¾åˆ°å†å²ä¼šè¯æ–‡ä»¶ï¼Œå¼€å§‹æ–°ä¼šè¯")
                return
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
            latest_file = max(session_files, key=os.path.getmtime)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¤ªæ—§ï¼ˆè¶…è¿‡24å°æ—¶ï¼‰
            file_age = time.time() - os.path.getmtime(latest_file)
            if file_age > 24 * 3600:  # 24å°æ—¶
                print(f"ğŸ“„ æœ€è¿‘ä¼šè¯æ–‡ä»¶è¿‡æ—§ï¼ˆ{file_age/3600:.1f}å°æ—¶ï¼‰ï¼Œå¼€å§‹æ–°ä¼šè¯")
                return
            
            # åŠ è½½å†å²ä¼šè¯
            with open(latest_file, 'r', encoding='utf-8') as f:
                session_data = json.load(f)
                
            self.conversation_history = session_data.get('conversation_history', [])
            self.current_turn = session_data.get('current_turn', 0)
            
            print(f"ğŸ“š å·²åŠ è½½å†å²ä¼šè¯: {len(self.conversation_history)} è½®å¯¹è¯")
            print(f"â° ä¼šè¯æ—¶é—´: {session_data.get('last_update', 'Unknown')}")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„å‡ è½®å¯¹è¯æ‘˜è¦
            self._show_recent_summary()
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å†å²ä¼šè¯å¤±è´¥: {e}")
            self.conversation_history = []
            self.current_turn = 0
    
    def _show_recent_summary(self) -> None:
        """æ˜¾ç¤ºæœ€è¿‘å¯¹è¯çš„æ‘˜è¦"""
        if not self.conversation_history:
            return
            
        print("ğŸ“‹ æœ€è¿‘å¯¹è¯æ‘˜è¦:")
        recent_conversations = self.conversation_history[-3:]  # æ˜¾ç¤ºæœ€è¿‘3è½®
        
        for i, conv in enumerate(recent_conversations, 1):
            user_text = conv.get('user_text', 'No transcript')
            ai_text = conv.get('ai_text', 'No response')
            
            # æˆªæ–­é•¿æ–‡æœ¬
            user_preview = user_text[:50] + "..." if len(user_text) > 50 else user_text
            ai_preview = ai_text[:50] + "..." if len(ai_text) > 50 else ai_text
            
            print(f"   {i}. ğŸ‘¤: {user_preview}")
            print(f"      ğŸ¤–: {ai_preview}")
        
        if len(self.conversation_history) > 3:
            print(f"   ... å…± {len(self.conversation_history)} è½®å¯¹è¯")
    
    def add_conversation_turn(self, user_text: str, ai_text: str, 
                            user_audio_duration: float = 0.0,
                            ai_audio_duration: float = 0.0) -> None:
        """æ·»åŠ ä¸€è½®å¯¹è¯"""
        with self._lock:
            self.current_turn += 1
            
            conversation_turn = {
                'turn_id': self.current_turn,
                'timestamp': datetime.now().isoformat(),
                'user_text': user_text.strip(),
                'ai_text': ai_text.strip(),
                'user_audio_duration': user_audio_duration,
                'ai_audio_duration': ai_audio_duration,
                'metadata': {
                    'user_text_length': len(user_text),
                    'ai_text_length': len(ai_text),
                    'session_id': self.session_id
                }
            }
            
            self.conversation_history.append(conversation_turn)
            
            # ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶
            self._save_to_file()
            
            print(f"ğŸ’¾ å·²ä¿å­˜ç¬¬ {self.current_turn} è½®å¯¹è¯")
            print(f"ğŸ“Š å¯¹è¯ç»Ÿè®¡: ç”¨æˆ·{len(user_text)}å­—, AI{len(ai_text)}å­—")
    
    def get_context_for_ai(self, max_length: Optional[int] = None) -> str:
        """è·å–ç»™AIçš„ä¸Šä¸‹æ–‡"""
        if not self.conversation_history:
            return ""
        
        max_length = max_length or self.max_context_length
        
        # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context_parts = ["ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼Œè¯·å‚è€ƒè¿™äº›ä¿¡æ¯å›ç­”æˆ‘çš„é—®é¢˜ï¼š\n"]
        
        # ä»æœ€æ–°çš„å¯¹è¯å¼€å§‹æ·»åŠ 
        total_length = len(context_parts[0])
        added_turns = 0
        
        for conv in reversed(self.conversation_history):
            turn_text = f"\nç¬¬{conv['turn_id']}è½®å¯¹è¯ï¼š\n"
            turn_text += f"ç”¨æˆ·: {conv['user_text']}\n"
            turn_text += f"AI: {conv['ai_text']}\n"
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé•¿åº¦é™åˆ¶
            if total_length + len(turn_text) > max_length:
                break
                
            context_parts.insert(1, turn_text)  # æ’å…¥åˆ°å¼€å¤´ï¼ˆæ—¶é—´é¡ºåºï¼‰
            total_length += len(turn_text)
            added_turns += 1
        
        # å¦‚æœæ·»åŠ çš„è½®æ•°è¾ƒå°‘ï¼Œå°è¯•ç”Ÿæˆæ‘˜è¦
        if added_turns < len(self.conversation_history) and len(self.conversation_history) > 5:
            summary = self._generate_conversation_summary()
            if summary:
                context_parts.insert(1, f"\næ—©æœŸå¯¹è¯æ‘˜è¦: {summary}\n")
        
        context = "".join(context_parts)
        context += "\nè¯·åŸºäºä»¥ä¸Šå¯¹è¯å†å²ï¼Œè‡ªç„¶åœ°å›ç­”æˆ‘çš„æ–°é—®é¢˜ï¼š"
        
        print(f"ğŸ§  ä¸ºAIç”Ÿæˆä¸Šä¸‹æ–‡: {len(context)}å­—, åŒ…å«{added_turns}è½®å¯¹è¯")
        return context
    
    def _generate_conversation_summary(self) -> str:
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        if len(self.conversation_history) < 5:
            return ""
            
        # è·å–æ—©æœŸå¯¹è¯ï¼ˆé™¤äº†æœ€è¿‘5è½®ï¼‰
        early_conversations = self.conversation_history[:-5]
        
        # æå–å…³é”®ä¿¡æ¯
        topics = set()
        key_info = []
        
        for conv in early_conversations:
            user_text = conv['user_text'].lower()
            ai_text = conv['ai_text']
            
            # ç®€å•çš„å…³é”®è¯æå–
            if any(keyword in user_text for keyword in ['ä»‹ç»', 'æ˜¯ä»€ä¹ˆ', 'æ€ä¹ˆæ ·', 'å¦‚ä½•']):
                key_info.append(f"ç”¨æˆ·è¯¢é—®äº†{conv['user_text'][:30]}")
            
            if any(keyword in user_text for keyword in ['å¤©æ°”', 'æ—¶é—´', 'æ—¥æœŸ']):
                topics.add('æ—¥å¸¸æŸ¥è¯¢')
            elif any(keyword in user_text for keyword in ['å­¦ä¹ ', 'å·¥ä½œ', 'é¡¹ç›®']):
                topics.add('å­¦ä¹ å·¥ä½œ')
            elif any(keyword in user_text for keyword in ['å¸®åŠ©', 'é—®é¢˜', 'è§£å†³']):
                topics.add('é—®é¢˜è§£å†³')
        
        # ç”Ÿæˆæ‘˜è¦
        summary_parts = []
        if topics:
            summary_parts.append(f"ä¸»è¦è¯é¢˜: {', '.join(topics)}")
        if key_info:
            summary_parts.append(f"å…³é”®ä¿¡æ¯: {'; '.join(key_info[:3])}")
        
        summary_parts.append(f"å…±{len(early_conversations)}è½®æ—©æœŸå¯¹è¯")
        
        return "; ".join(summary_parts)
    
    def _save_to_file(self) -> None:
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        try:
            session_data = {
                'session_id': self.session_id,
                'created_at': datetime.now().isoformat(),
                'last_update': datetime.now().isoformat(),
                'current_turn': self.current_turn,
                'conversation_history': self.conversation_history,
                'statistics': {
                    'total_turns': len(self.conversation_history),
                    'total_user_chars': sum(len(c['user_text']) for c in self.conversation_history),
                    'total_ai_chars': sum(len(c['ai_text']) for c in self.conversation_history),
                    'session_duration_minutes': self._get_session_duration()
                }
            }
            
            # åŸå­å†™å…¥ï¼ˆå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½åï¼‰
            temp_file = self.session_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, ensure_ascii=False, indent=2)
            
            temp_file.rename(self.session_file)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ä¼šè¯æ–‡ä»¶å¤±è´¥: {e}")
    
    def _get_session_duration(self) -> float:
        """è·å–ä¼šè¯æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        if not self.conversation_history:
            return 0.0
            
        try:
            first_time = datetime.fromisoformat(self.conversation_history[0]['timestamp'])
            last_time = datetime.fromisoformat(self.conversation_history[-1]['timestamp'])
            duration = (last_time - first_time).total_seconds() / 60
            return round(duration, 1)
        except:
            return 0.0
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        if not self.conversation_history:
            return {'total_turns': 0}
            
        stats = {
            'total_turns': len(self.conversation_history),
            'session_duration_minutes': self._get_session_duration(),
            'total_user_chars': sum(len(c['user_text']) for c in self.conversation_history),
            'total_ai_chars': sum(len(c['ai_text']) for c in self.conversation_history),
            'average_user_response_length': sum(len(c['user_text']) for c in self.conversation_history) / len(self.conversation_history),
            'average_ai_response_length': sum(len(c['ai_text']) for c in self.conversation_history) / len(self.conversation_history),
            'current_context_length': len(self.get_context_for_ai()),
            'session_id': self.session_id,
            'cache_file': str(self.session_file)
        }
        
        return stats
    
    def cleanup_old_sessions(self, days_to_keep: int = 7) -> None:
        """æ¸…ç†æ—§çš„ä¼šè¯æ–‡ä»¶"""
        try:
            cutoff_time = time.time() - (days_to_keep * 24 * 3600)
            
            session_files = list(self.cache_dir.glob("session_*.json"))
            removed_count = 0
            
            for file_path in session_files:
                if os.path.getmtime(file_path) < cutoff_time:
                    file_path.unlink()
                    removed_count += 1
            
            if removed_count > 0:
                print(f"ğŸ§¹ æ¸…ç†äº† {removed_count} ä¸ªæ—§ä¼šè¯æ–‡ä»¶ï¼ˆè¶…è¿‡{days_to_keep}å¤©ï¼‰")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ—§ä¼šè¯æ–‡ä»¶å¤±è´¥: {e}")
    
    def export_conversation(self, export_format: str = "markdown") -> str:
        """å¯¼å‡ºå¯¹è¯å†å²"""
        if not self.conversation_history:
            return "æ²¡æœ‰å¯¹è¯å†å²å¯ä»¥å¯¼å‡º"
            
        if export_format.lower() == "markdown":
            return self._export_as_markdown()
        elif export_format.lower() == "text":
            return self._export_as_text()
        else:
            return json.dumps(self.conversation_history, ensure_ascii=False, indent=2)
    
    def _export_as_markdown(self) -> str:
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        lines = [
            f"# å¯¹è¯å†å²å¯¼å‡º",
            f"",
            f"**ä¼šè¯ID**: {self.session_id}",
            f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**å¯¹è¯è½®æ•°**: {len(self.conversation_history)}",
            f"**ä¼šè¯æ—¶é•¿**: {self._get_session_duration():.1f} åˆ†é’Ÿ",
            f"",
            f"---",
            f""
        ]
        
        for i, conv in enumerate(self.conversation_history, 1):
            timestamp = datetime.fromisoformat(conv['timestamp']).strftime('%H:%M:%S')
            lines.extend([
                f"## ç¬¬ {i} è½®å¯¹è¯ ({timestamp})",
                f"",
                f"**ğŸ‘¤ ç”¨æˆ·**: {conv['user_text']}",
                f"",
                f"**ğŸ¤– AI**: {conv['ai_text']}",
                f"",
                f"---",
                f""
            ])
        
        return "\n".join(lines)
    
    def _export_as_text(self) -> str:
        """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        lines = [
            f"å¯¹è¯å†å²å¯¼å‡º - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"ä¼šè¯ID: {self.session_id}",
            f"å¯¹è¯è½®æ•°: {len(self.conversation_history)}",
            f"ä¼šè¯æ—¶é•¿: {self._get_session_duration():.1f} åˆ†é’Ÿ",
            f"",
            f"=" * 50,
            f""
        ]
        
        for i, conv in enumerate(self.conversation_history, 1):
            timestamp = datetime.fromisoformat(conv['timestamp']).strftime('%H:%M:%S')
            lines.extend([
                f"ç¬¬ {i} è½®å¯¹è¯ ({timestamp})",
                f"",
                f"ç”¨æˆ·: {conv['user_text']}",
                f"",
                f"AI: {conv['ai_text']}",
                f"",
                f"-" * 30,
                f""
            ])
        
        return "\n".join(lines)
    
    def close(self) -> None:
        """å…³é—­ç¼“å­˜ç®¡ç†å™¨"""
        try:
            # æœ€åä¸€æ¬¡ä¿å­˜
            self._save_to_file()
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = self.get_conversation_stats()
            print(f"\nğŸ“Š å¯¹è¯ä¼šè¯ç»Ÿè®¡:")
            print(f"   æ€»è½®æ•°: {stats['total_turns']}")
            print(f"   ä¼šè¯æ—¶é•¿: {stats['session_duration_minutes']:.1f} åˆ†é’Ÿ")
            print(f"   ç”¨æˆ·æ€»å­—æ•°: {stats['total_user_chars']}")
            print(f"   AIæ€»å­—æ•°: {stats['total_ai_chars']}")
            print(f"   ä¼šè¯æ–‡ä»¶: {stats['cache_file']}")
            
            # æ¸…ç†æ—§æ–‡ä»¶
            self.cleanup_old_sessions()
            
            print("ğŸ’¾ å¯¹è¯ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­")
            
        except Exception as e:
            print(f"âš ï¸ å…³é—­ç¼“å­˜ç®¡ç†å™¨æ—¶å‡ºé”™: {e}") 