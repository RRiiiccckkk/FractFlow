# FractFlow

FractFlow is a fractal intelligence architecture that decomposes intelligence into nestable Agent-Tool units, building dynamically evolving distributed cognitive systems through recursive composition.

## Design Philosophy

FractFlow is a fractal intelligence architecture that decomposes intelligence into nestable Agent-Tool units, building dynamically evolving distributed cognitive systems through recursive composition.

Each agent not only possesses cognitive capabilities but also has the ability to call other agents, forming self-referential, self-organizing, and self-adaptive intelligent flows.

Similar to how each tentacle of an octopus has its own brain in a collaborative structure, FractFlow achieves structurally malleable and behaviorally evolving distributed intelligence through the combination and coordination of modular intelligence.

## Installation

Please install "uv" first: https://docs.astral.sh/uv/#installation

```bash
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt
```

Note: The project is still under development. If dependencies are not satisfied, please install manually: `uv pip install XXXX`.

### Advantages of uv Environment Isolation

When the tool ecosystem expands, different tools may require different dependency package versions. uv provides powerful environment isolation capabilities:

```bash
# Create independent environment for specific tools
cd tools/your_specific_tool/
uv venv
source .venv/bin/activate

# Install tool-specific dependencies
uv pip install specific_package==1.2.3

# Tool will use independent environment when running
python your_tool_agent.py
```

**Particularly useful scenarios**:
- **Third-party tool integration**: Avoid dependency conflicts when wrapping tools from other GitHub repositories
- **Version compatibility**: Different tools need different versions of the same library
- **Experimental development**: Test new dependencies without affecting the main environment

This flexible environment management allows FractFlow to support more complex and diverse tool ecosystems.

## Environment Configuration

### .env File Setup

Create a `.env` file in the project root directory to configure necessary API keys:

```bash
# Create .env file
touch .env
```

Example `.env` file content:

```env
# AI Model API Keys (configure at least one)

# DeepSeek API Key
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenAI API Key (for GPT models and image generation)
OPENAI_API_KEY=your_openai_api_key_here
COMPLETION_API_KEY=your_openai_api_key_here

# Qwen API Key (Alibaba Cloud Tongyi Qianwen)
QWEN_API_KEY=your_qwen_api_key_here

# Optional: Custom API Base URLs
# DEEPSEEK_BASE_URL=https://api.deepseek.com
# OPENAI_BASE_URL=https://api.openai.com/v1
```

### API Key Acquisition

#### DeepSeek (Recommended)
1. Visit [DeepSeek Open Platform](https://platform.deepseek.com/)
2. Register an account and obtain API key
3. Set `DEEPSEEK_API_KEY` environment variable

#### OpenAI
1. Visit [OpenAI API Platform](https://platform.openai.com/api-keys)
2. Create API key
3. Set `OPENAI_API_KEY` and `COMPLETION_API_KEY` environment variables
4. **Note**: Image generation functionality requires OpenAI API key

#### Qwen (Optional)
1. Visit [Alibaba Cloud DashScope](https://dashscope.console.aliyun.com/)
2. Enable Tongyi Qianwen service and obtain API key
3. Set `QWEN_API_KEY` environment variable

### Configuration Validation

Verify that environment configuration is correct:

```bash
# Test basic functionality
python tools/core/weather/weather_agent.py --query "How is the weather in New York?"
```

## Quick Start

### ğŸš€ Frontend Assistant - Recommended Entry Point

The easiest way to experience FractFlow is through our unified frontend interface:

```bash
# Launch interactive mode selection
python å‰ç«¯/hkust_ai_assistant_entry.py

# Choose from 4 modes:
# 1. ğŸ“š Academic Q&A Mode - Academic consulting and research support
# 2. ğŸ¤ Default Voice Mode - Qwen Omni voice, quick conversation  
# 3. ğŸ“ Principal Ni Voice Mode - Principal Ni's voice cloning, authoritative academic communication
# 4. âš¡ Manual Real-time Interruption Mode - Millisecond-level interruption, ultimate control experience
```

**Direct mode launch**:
```bash
python å‰ç«¯/hkust_ai_assistant_entry.py --mode academic         # Academic mode
python å‰ç«¯/hkust_ai_assistant_entry.py --mode voice           # Default voice mode
python å‰ç«¯/hkust_ai_assistant_entry.py --mode ni-voice        # Principal Ni voice mode  
python å‰ç«¯/hkust_ai_assistant_entry.py --mode manual-interrupt # Manual interruption mode
```

### Basic Tool Usage

Each tool in FractFlow supports three running modes:

```bash
# MCP Server mode (default, no need to start manually, usually started automatically by programs)
python tools/core/file_io/file_io_agent.py

# Interactive mode
python tools/core/file_io/file_io_agent.py --interactive

# Single query mode
python tools/core/file_io/file_io_agent.py --query "Read README.md file"
```

### First Tool Run

Let's run a simple file operation:

```bash
python tools/core/file_io/file_io_agent.py --query "Read the first 10 lines of README.md file in project root directory"
```

## Tool Development Tutorial

### 5-Minute Quick Start: Hello World Tool

Creating your first FractFlow tool only requires inheriting `ToolTemplate` and defining two required attributes:

```python
# my_hello_tool.py
import os
import sys

# Add project root directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '../..'))
sys.path.append(project_root)

from FractFlow.tool_template import ToolTemplate

class HelloTool(ToolTemplate):
    """Simple greeting tool"""
    
    SYSTEM_PROMPT = """
You are a friendly greeting assistant.
When users provide names, please give personalized greetings.
Please reply in Chinese, maintaining a friendly and enthusiastic tone.
"""
    
    TOOL_DESCRIPTION = """
Tool for generating personalized greetings.

Parameters:
    query: str - User's name or greeting request

Returns:
    str - Personalized greeting message
"""

if __name__ == "__main__":
    HelloTool.main()
```

Run your tool:

```bash
# Interactive mode
python my_hello_tool.py --interactive

# Single query
python my_hello_tool.py --query "My name is Zhang San"
```

**Core Concept Understanding:**
- `SYSTEM_PROMPT`: Defines agent behavior and response style
- `TOOL_DESCRIPTION`: **Important**: This is the tool usage manual exposed to upper-layer Agents. In fractal intelligence, upper-layer Agents read this description to understand how to call lower-layer tools
- `ToolTemplate`: Provides unified runtime framework (MCP server, interactive, single query - three modes)

### 30-Minute Practice: Three Classic Scenarios

#### Scenario 1: File Operation-Based Tool Development

**Reference Implementation**: [`tools/core/file_io/file_io_agent.py`](tools/core/file_io/file_io_agent.py)

**Extension Points**:
- Inherit `ToolTemplate` base class to get three running mode support
- Reference `file_io_mcp.py` as underlying file operation tool
- Customize `SYSTEM_PROMPT` to implement specific file analysis logic
- Configure appropriate iteration count and model parameters

**Creation Steps**:
1. Copy basic structure of file_io_agent.py
2. Modify `SYSTEM_PROMPT` to add your analysis logic (such as statistical analysis, content summarization, etc.)
3. Adjust `TOOL_DESCRIPTION` to describe new functionality features
4. Adjust parameters in `create_config()` according to task complexity

**Core Configuration Example**:
```python
TOOLS = [("tools/core/file_io/file_io_mcp.py", "file_operations")]
# Add your professional analysis prompts to SYSTEM_PROMPT
```

#### Scenario 2: Image Generation Integration Tool Development

**Reference Implementation**: [`tools/core/gpt_imagen/gpt_imagen_agent.py`](tools/core/gpt_imagen/gpt_imagen_agent.py)

**Core Features**:
- Support both text-to-image and image editing modes
- Strict path parameter preservation strategy
- Automatic prompt optimization mechanism

**Customization Directions**:
- **Prompt Engineering**: Modify `SYSTEM_PROMPT` to add specific prompt optimization strategies
- **Post-processing Integration**: Combine with other image processing tools for composite functionality
- **Batch Processing**: Extend to support multi-image generation workflows
- **Style Customization**: Optimize for specific artistic styles or purposes

**Key Configuration**:
```python
TOOLS = [("tools/core/gpt_imagen/gpt_imagen_mcp.py", "gpt_image_generator_operations")]
# Define your image generation strategy in SYSTEM_PROMPT
```

#### Scenario 3: Fractal Intelligence Demonstration (Visual Article Agent)

**Complete Implementation**: [`tools/composite/visual_article_agent.py`](tools/composite/visual_article_agent.py)

**Extension Directions**:
- Add more professional tools (such as web search, data analysis)
- Implement more complex content generation strategies
- Integrate different file format outputs

**Core Understanding of Fractal Intelligence**:
- **Recursive Composition**: Tools can call other tools, forming multi-layer intelligent structures
- **Professional Division**: Each tool focuses on specific domains, achieving complex functionality through combination
- **Adaptive Coordination**: High-level tools dynamically select and combine low-level tools based on task requirements

### Deep Mastery: Architectural Principles

#### ToolTemplate Lifecycle

```python
# 1. Class Definition Phase
class MyTool(ToolTemplate):
    SYSTEM_PROMPT = "..."      # Define agent behavior
    TOOL_DESCRIPTION = "..."   # Define tool interface
    TOOLS = [...]              # Declare dependent tools

# 2. Initialization Phase
@classmethod
async def create_agent(cls):
    config = cls.create_config()           # Create configuration
    agent = Agent(config=config)           # Create agent
    await cls._add_tools_to_agent(agent)   # Add tools
    return agent

# 3. Runtime Phase
def main(cls):
    # Choose running mode based on command line arguments
    if args.interactive:
        cls._run_interactive()      # Interactive mode
    elif args.query:
        cls._run_single_query()     # Single query
    else:
        cls._run_mcp_server()       # MCP server mode
```

#### Configuration System Details

FractFlow provides three-level configuration customization:

```python
# Level 1: Use default configuration
class SimpleTool(ToolTemplate):
    SYSTEM_PROMPT = "..."
    TOOL_DESCRIPTION = "..."
    # Automatically use DeepSeek default configuration

# Level 2: Partial customization
class CustomTool(ToolTemplate):
    SYSTEM_PROMPT = "..."
    TOOL_DESCRIPTION = "..."
    
    @classmethod
    def create_config(cls):
        return ConfigManager(
            provider='deepseek',           # Switch model provider
            openai_model='deepseek-reasoner',       # Specify model
            max_iterations=20           # Adjust iteration count
        )

# Level 3: Full customization
class AdvancedTool(ToolTemplate):
    SYSTEM_PROMPT = "..."
    TOOL_DESCRIPTION = "..."
    
    @classmethod
    def create_config(cls):
        from dotenv import load_dotenv
        load_dotenv()
        
        return ConfigManager(
            provider='qwen',
            anthropic_model='qwen-plus',
            max_iterations=50,
            temperature=0.7,
            custom_system_prompt=cls.SYSTEM_PROMPT + "\nAdditional instructions...",
            tool_calling_version='turbo',
            timeout=120
        )
```

## Tool Showcase

### Core Tools

#### File I/O Agent - File Operation Expert
```bash
# Basic file operations
python tools/core/file_io/file_io_agent.py --query "Read config.json file"
python tools/core/file_io/file_io_agent.py --query "Write 'Hello World' to output.txt"

# Advanced operations
python tools/core/file_io/file_io_agent.py --query "Read lines 100-200 of large file data.csv"
python tools/core/file_io/file_io_agent.py --query "Delete all lines containing 'ERROR' from temp.log"
```

**Feature Highlights**:
- Intelligent file operations: read, write, delete, insert
- Large file chunked processing
- Line-level precise operations
- Automatic directory creation

#### GPT Imagen Agent - AI Image Generation
```bash
# Image generation
python tools/core/gpt_imagen/gpt_imagen_agent.py --query "Generate image: save_path='spring_garden.png' prompt='a beautiful spring garden with flowers'"
python tools/core/gpt_imagen/gpt_imagen_agent.py --query "Generate image: save_path='robot.png' prompt='futuristic robot illustration'"
```

#### Web Search Agent - Web Search
```bash
# Web search
python tools/core/websearch/websearch_agent.py --query "Latest AI technology developments"
python tools/core/websearch/websearch_agent.py --query "Python performance optimization methods"
```

#### Weather Agent - Weather Query Assistant (US Only)
```bash
# Weather queries (US cities only)
python tools/core/weather/weather_agent.py --query "Weather in New York today"
python tools/core/weather/weather_agent.py --query "5-day forecast for San Francisco"
```

This tool can only query weather information within the United States.

#### Visual Question Answer - Visual Q&A
```bash
# Image understanding (based on Qwen-VL-Plus model)
python tools/core/visual_question_answer/vqa_agent.py --query "Image: /path/to/image.jpg What objects are in this picture?"
python tools/core/visual_question_answer/vqa_agent.py --query "Image: /path/to/photo.png Describe the scene in detail"
```

#### Realtime Voice Interactive - Real-time Voice Assistant

FractFlow provides an advanced real-time voice interaction system with support for multiple modes including the revolutionary **Manual Real-time Interruption Mode**:

```bash
# Frontend integration (recommended - supports four mode selection)
python å‰ç«¯/hkust_ai_assistant_entry.py
# Choose from: 1.Academic Q&A 2.Default Voice 3.Principal Ni Voice 4.Manual Real-time Interruption

# Command line direct launch
python å‰ç«¯/hkust_ai_assistant_entry.py --mode academic         # Academic Q&A mode
python å‰ç«¯/hkust_ai_assistant_entry.py --mode voice           # Default voice mode  
python å‰ç«¯/hkust_ai_assistant_entry.py --mode ni-voice        # Principal Ni voice mode
python å‰ç«¯/hkust_ai_assistant_entry.py --mode manual-interrupt # Manual real-time interruption mode

# Or use short parameters
python å‰ç«¯/hkust_ai_assistant_entry.py --voice-interactive      # Default voice
python å‰ç«¯/hkust_ai_assistant_entry.py --ni-voice-interactive   # Principal Ni voice
python å‰ç«¯/hkust_ai_assistant_entry.py --manual-interrupt       # Manual interruption

# Direct tool invocation
python tools/core/realtime_voice_interactive/realtime_voice_interactive.py     # Default voice
python tools/core/realtime_voice_interactive/realtime_voice_interactive.py ni  # Principal Ni voice

# Manual Real-time Interruption Mode (New!)
python tools/core/æ‰‹åŠ¨å®æ—¶æ‰“æ–­/è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­.py                    # Default voice version
python tools/core/æ‰‹åŠ¨å®æ—¶æ‰“æ–­/è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­_å€ªæ ¡ç‰ˆ.py              # Principal Ni voice version
```

**ğŸ¯ Four Interactive Modes Comparison**:

| Mode | Voice Source | Use Case | Technical Features |
|------|-------------|----------|-------------------|
| ğŸ“š Academic Q&A | Text reply | Academic consulting, research support | Professional, rigorous, detailed |
| ğŸ¤ Default Voice | Qwen Omni built-in | Daily conversation, quick interaction | Stable, fast, ready-to-use |
| ğŸ“ Principal Ni Voice | Voice cloning technology | Formal occasions, academic communication | Authoritative, professional, streaming playback |
| âš¡ Manual Real-time Interruption | Dual voice support | Ultimate control experience | **Millisecond-level interruption**, **zero-crash guarantee** |

**Feature Highlights**:
- ğŸ¤ **Real-time Speech Recognition**: Natural Chinese voice input with automatic text conversion
- ğŸ”Š **Multiple Voice Modes**: Default system voice + Principal Ni's cloned voice + Manual control mode
- âš¡ **Ultra-fast Interruption**: 0.01ms response time with multi-level interruption mechanism
- ğŸµ **Dynamic Volume Detection**: Adaptive background noise calibration and continuity verification
- ğŸš€ **Streaming TTS Playback**: Sentence-by-sentence generation for dramatically improved response speed (Principal Ni mode)
- ğŸ§  **Fractal Intelligence**: Nested agent calling with natural language priority
- ğŸ¯ **Enterprise-grade Experience**: Professional voice interaction solution

### âš¡ Manual Real-time Interruption Mode - Revolutionary Control Experience

The **Manual Real-time Interruption Mode** represents a breakthrough in voice interaction technology, providing unprecedented control precision:

#### ğŸš€ Quick Start
```bash
# Interactive mode selection (recommended)
python å‰ç«¯/hkust_ai_assistant_entry.py
# Select option 4: âš¡ Manual Real-time Interruption Mode

# Direct command line launch
python å‰ç«¯/hkust_ai_assistant_entry.py --mode manual-interrupt

# Direct tool execution
python tools/core/æ‰‹åŠ¨å®æ—¶æ‰“æ–­/è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­.py                    # Default voice
python tools/core/æ‰‹åŠ¨å®æ—¶æ‰“æ–­/è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­_å€ªæ ¡ç‰ˆ.py              # Principal Ni voice
```

#### ğŸ® Control Methods
```
Manual Control Instructions:
1. Press [Enter] to start recording
2. Speak your question
3. Press [Enter] again to stop recording and send
4. During AI response, press [Enter] to interrupt immediately âš¡
5. Type 'q' or 'quit' to exit
```

#### ğŸ“Š Performance Metrics
| Metric | Before Optimization | After Optimization | Improvement |
|--------|-------------------|-------------------|-------------|
| Interruption Delay | 500-1000ms | **<50ms** | **20x faster** |
| HTTP Chunk Size | 1024 bytes | 256 bytes | 4x smaller |
| Audio Chunk Size | Large blocks | 64 bytes | 16x smaller |
| Response Precision | Second-level | **Millisecond-level** | 1000x improvement |
| Crash Rate | Occasional | **0%** | **100% reliability** |

#### ğŸ”§ Technical Architecture
- **Multi-layer Stop Mechanism**: stop_flag + stop_event dual control
- **Forced Audio Stream Termination**: Immediate HTTP session closure
- **Thread-safe Optimization**: Independent playback threads with lock protection
- **Intelligent Memory Monitoring**: Three-level warning system with automatic cleanup
- **Zero-crash Guarantee**: Complete resolution of PyAudio segmentation fault

#### ğŸ’¡ Core Advantages
- âš¡ **Millisecond Response**: <50ms interruption delay, 20x performance boost
- ğŸ“ **Dual Voice Support**: Both default system voice and Principal Ni voice
- ğŸ§  **Intelligent Context Memory**: Automatic conversation history management  
- ğŸ“Š **Zero Crash Guarantee**: Production-level stability with 100% reliability
- ğŸ”§ **MCP Server Support**: Can be called as a tool by other intelligent agents

#### ğŸ“ File Structure
```
tools/core/æ‰‹åŠ¨å®æ—¶æ‰“æ–­/
â”œâ”€â”€ README.md                          # Complete documentation
â”œâ”€â”€ æ‰‹åŠ¨å®æ—¶æ‰“æ–­_agent.py              # Default voice version
â”œâ”€â”€ æ‰‹åŠ¨å®æ—¶æ‰“æ–­_å€ªæ ¡ç‰ˆ_agent.py        # Principal Ni voice version
â”œâ”€â”€ æ‰‹åŠ¨å®æ—¶æ‰“æ–­_mcp.py               # Default MCP server
â”œâ”€â”€ æ‰‹åŠ¨å®æ—¶æ‰“æ–­_å€ªæ ¡ç‰ˆ_mcp.py         # Principal Ni MCP server
â”œâ”€â”€ è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­.py              # Quick launch script (default)
â”œâ”€â”€ è¿è¡Œ_æ‰‹åŠ¨å®æ—¶æ‰“æ–­_å€ªæ ¡ç‰ˆ.py        # Quick launch script (Principal Ni)
â””â”€â”€ conversation_cache_manager.py      # Conversation cache manager
```

**General Usage Instructions**:
- Speak naturally to ask questions
- The system automatically interrupts AI responses when you start speaking (auto modes)
- Manual mode: Use Enter key for complete control over conversation flow
- Wait for complete AI responses before continuing the conversation
- Press Ctrl+C to exit
- Support text commands: "voice off" to switch to text mode

### Composite Tools

#### Visual Article Agent - Illustrated Article Generator

This is a typical representative of fractal intelligence, coordinating multiple tools to generate complete text-image content:

```bash
# Generate complete illustrated articles
python tools/composite/visual_article_agent.py --query "Write an article about AI development with illustrations"

# Customized articles
python tools/composite/visual_article_agent.py --query "è®¾å®šï¼šä¸€ä¸ªè§†è§‰è¯†åˆ«AIç»Ÿæ²»ç¤¾ä¼šçš„ä¸–ç•Œï¼Œäººç±»åªèƒ½ä¾èµ–å®ƒè§£é‡Šå›¾åƒã€‚ä¸»äººå…¬å´æ‹¥æœ‰"äººç±»è§†è§‰ç›´è§‰"ï¼Œå¹¶å› æ­¤è¢«æ€€ç–‘ä¸ºå¼‚å¸¸ä¸ªä½“ã€‚
è¦æ±‚ï¼šä»¥ç¬¬ä¸€äººç§°ï¼Œå†™ä¸€æ®µå‰§æƒ…ç‰‡æ®µï¼Œå±•ç°ä»–ä¸AIæ¨¡å‹å¯¹å›¾åƒç†è§£çš„å†²çªã€‚
æƒ…ç»ªåŸºè°ƒï¼šå†·å³»ã€æ€€ç–‘ã€è¯—æ€§ã€‚"
```


![](assets/visual_article.gif)

**Workflow**:
1. Analyze article requirements and structure
2. Use `file_manager_agent` to write chapter content
3. Use `image_creator_agent` to generate supporting illustrations
4. Integrate into complete Markdown document

**Output Example**:
```
output/visual_article_generator/ai_development/
â”œâ”€â”€ article.md           # Complete article
â””â”€â”€ images/             # Supporting images
    â”œâ”€â”€ section1-fig1.png
    â”œâ”€â”€ section2-fig1.png
    â””â”€â”€ section3-fig1.png
```

#### Web Save Agent - Intelligent Web Saving
```bash
# Intelligent web saving (fractal intelligence example)
python tools/composite/web_save_agent.py --query "Search for latest Python tutorials and save to a comprehensive guide file"
python tools/composite/web_save_agent.py --query "Find information about machine learning and create an organized report"
```

**Feature Highlights**:
- Fractal intelligence combining web search and file saving
- Intelligent content organization and structuring
- Automatic file path management
- Multi-round search support

## API Reference

### Two Tool Development Approaches

FractFlow provides two flexible tool development approaches to meet different development needs:

#### Approach 1: Inherit ToolTemplate (Recommended)

Standardized tool development approach with automatic support for three running modes:

```python
from FractFlow.tool_template import ToolTemplate

class MyTool(ToolTemplate):
    """Standard tool class"""
    
    SYSTEM_PROMPT = """Your tool behavior instructions"""
    TOOL_DESCRIPTION = """Tool functionality description"""
    
    # Optional: depend on other tools
    TOOLS = [("path/to/tool.py", "tool_name")]
    
    @classmethod
    def create_config(cls):
        return ConfigManager(...)

# Automatically supports three running modes
# python my_tool.py                    # MCP server mode
# python my_tool.py --interactive      # Interactive mode  
# python my_tool.py --query "..."      # Single query mode
```

#### Approach 2: Custom Agent Class

Completely autonomous development approach:

```python
from FractFlow.agent import Agent
from FractFlow.infra.config import ConfigManager

async def main():
    # Custom configuration
    config = ConfigManager(
        provider='deepseek',
        deepseek_model='deepseek-chat',
        max_iterations=5
    )
    
    # Create Agent
    agent = Agent(config=config, name='my_agent')
    
    # Manually add tools
    agent.add_tool("./tools/weather/weather_mcp.py", "forecast_tool")
    
    # Initialize and use
    await agent.initialize()
    result = await agent.process_query("Your query")
    await agent.shutdown()
```

### ToolTemplate Base Class

FractFlow's core base class providing unified tool development framework:

```python
class ToolTemplate:
    """FractFlow tool template base class"""
    
    # Required attributes
    SYSTEM_PROMPT: str      # Agent system prompt
    TOOL_DESCRIPTION: str   # Tool functionality description
    
    # Optional attributes
    TOOLS: List[Tuple[str, str]] = []        # Dependent tools list
    MCP_SERVER_NAME: Optional[str] = None    # MCP server name
    
    # Core methods
    @classmethod
    def create_config(cls) -> ConfigManager:
        """Create configuration - can be overridden"""
        pass
    
    @classmethod
    async def create_agent(cls) -> Agent:
        """Create agent instance"""
        pass
    
    @classmethod
    def main(cls):
        """Main entry point - supports three running modes"""
        pass
```

#### Key Attribute Details

**Important Role of TOOL_DESCRIPTION**:

In FractFlow's fractal intelligence architecture, `TOOL_DESCRIPTION` is not just documentation for developers, but more importantly:

- **Reference manual for upper-layer Agents**: When a composite tool (like visual_article_agent) calls lower-layer tools, the upper-layer Agent reads the lower-layer tool's TOOL_DESCRIPTION to understand how to use it correctly
- **Tool interface specification**: Defines input parameter formats, return value structures, usage scenarios, etc.
- **Basis for intelligent calling**: Upper-layer Agents determine when and how to call specific tools based on this description

**Example**: When visual_article_agent calls file_io tool:
```python
# Upper-layer Agent reads file_io tool's TOOL_DESCRIPTION
# Then constructs call requests based on parameter formats described
TOOLS = [("tools/core/file_io/file_io_mcp.py", "file_operations")]
```

Therefore, writing clear and accurate TOOL_DESCRIPTION is crucial for the correct operation of fractal intelligence. However, TOOL_DESCRIPTION should not be too long.

**SYSTEM_PROMPT Writing Guidelines**:

Unlike TOOL_DESCRIPTION which faces upper-layer Agents, `SYSTEM_PROMPT` is the internal behavior instruction for the current Agent. Reference visual_article_agent's practice:

**Structured Design**:
```python
# Reference: tools/composite/visual_article_agent.py
SYSTEM_PROMPT = """
ã€Strict Constraintsã€‘
âŒ Absolutely Forbidden: Direct content output
âœ… Must Execute: Complete tasks through tool calls

ã€Workflowã€‘
1. Analyze requirements
2. Call related tools
3. Verify results
"""
```

**Key Techniques**:
- **Clear Prohibitions**: Use `âŒ` to define what cannot be done, avoiding common errors
- **Forced Execution**: Use `âœ…` to specify required behavior patterns
- **Process-oriented**: Break complex tasks into clear steps
- **Verification Mechanism**: Require confirmation of results after each step

This design ensures consistency and predictability of Agent behavior, which is key to reliable operation of composite tools.

### Configuration Management

```python
from FractFlow.infra.config import ConfigManager

# Basic configuration
config = ConfigManager()

# Custom configuration
config = ConfigManager(
    provider='openai',              # Model provider: openai/anthropic/deepseek
    openai_model='gpt-4',          # Specific model
    max_iterations=20,             # Maximum iterations
    temperature=0.7,               # Generation temperature
    custom_system_prompt="...",    # Custom system prompt
    tool_calling_version='stable', # Tool calling version: stable/turbo
    timeout=120                    # Timeout setting
)
```

## File Organization
```
tools/
â”œâ”€â”€ core/                 # Core tools
â”‚   â””â”€â”€ your_tool/
â”‚       â”œâ”€â”€ your_tool_agent.py    # Main agent
â”‚       â”œâ”€â”€ your_tool_mcp.py      # MCP tool implementation
â”‚       â””â”€â”€ __init__.py
â””â”€â”€ composite/            # Composite tools
    â””â”€â”€ your_composite_tool.py
```
#### Naming Conventions
- File names: `snake_case`
- Class names: `PascalCase`

## ğŸ™ï¸ æ–°åŠŸèƒ½ï¼šåƒé—®Omniå®æ—¶è¯­éŸ³äº¤äº’

FractFlowç°åœ¨æ”¯æŒåŸºäºåƒé—®Omniçš„å®æ—¶è¯­éŸ³äº¤äº’åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- âš¡ **å®æ—¶è¯­éŸ³æ‰“æ–­** - åœ¨AIè¯´è¯æ—¶å¯ä»¥éšæ—¶æ‰“æ–­
- ğŸ¤ **æ™ºèƒ½è¯­éŸ³æ´»åŠ¨æ£€æµ‹** (VAD) - é™ä½é˜ˆå€¼æé«˜æ•æ„Ÿåº¦  
- ğŸ”Š **åŒå‘éŸ³é¢‘æµ** - æ”¯æŒåŒæ—¶å½•éŸ³å’Œæ’­æ”¾
- ğŸ§µ **å¤šçº¿ç¨‹å¤„ç†** - ç‹¬ç«‹çš„å½•éŸ³ã€å¤„ç†ã€æ’­æ”¾çº¿ç¨‹
- ğŸ”„ **WebSocketå®æ—¶é€šä¿¡** - ä¸åƒé—®Omni APIå»ºç«‹æŒä¹…è¿æ¥
- ğŸ“ **è¯­éŸ³è½¬å½•æ˜¾ç¤º** - å®æ—¶æ˜¾ç¤ºå¯¹è¯å†…å®¹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨uvå®‰è£…ï¼ˆæ¨èï¼‰
uv install

# æˆ–ä½¿ç”¨pip
pip install -r requirements.txt

# å®‰è£…éŸ³é¢‘ä¾èµ–
uv add pyaudio numpy
```

### é…ç½®APIå¯†é’¥

1. å¤åˆ¶é…ç½®æ¨¡æ¿ï¼š
```bash
cp config.env.example .env
```

2. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥ï¼š
```bash
QWEN_API_KEY=your_qwen_api_key_here
DASHSCOPE_API_KEY=your_dashscope_api_key_here
```

### è¯­éŸ³äº¤äº’ä½¿ç”¨

#### å®Œç¾ç‰ˆè¯­éŸ³èŠå¤©ï¼ˆæ¨èï¼‰
```bash
python perfect_voice_chat.py
```

#### å…¶ä»–è¯­éŸ³åŠŸèƒ½
```bash
# åŸºç¡€è¯­éŸ³èŠå¤©
python qwen_voice_chat.py

# å®Œæ•´åŠŸèƒ½å¯åŠ¨å™¨
python start_qwen_voice_complete.py

# è¯­éŸ³æ‰“æ–­æµ‹è¯•
python test_voice_interrupt.py

# éŸ³é¢‘è¯Šæ–­å·¥å…·
python audio_diagnostic.py

# macOSæƒé™ä¿®å¤
python macos_voice_permission_fix.py
```

## ğŸ¤ è¯­éŸ³ç³»ç»Ÿç‰¹æ€§

### æ™ºèƒ½è®¾å¤‡é€‰æ‹©
- è‡ªåŠ¨è¯†åˆ«å’Œé€‰æ‹©æœ€ä½³éº¦å…‹é£è®¾å¤‡
- ä¼˜å…ˆä½¿ç”¨MacBookå†…ç½®éº¦å…‹é£
- é¿å…å…¼å®¹æ€§é—®é¢˜è®¾å¤‡ï¼ˆå¦‚æŸäº›è“ç‰™è€³æœºï¼‰

### ä¼˜åŒ–çš„VADå‚æ•°
- threshold: 0.15 (å¹³è¡¡æ•æ„Ÿåº¦)
- prefix_padding_ms: 150 (é€‚ä¸­çš„å‰ç¼€)
- silence_duration_ms: 400 (é€‚ä¸­çš„é™éŸ³æ—¶é—´)

### å®æ—¶æ‰“æ–­æœºåˆ¶
- æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯ç«‹å³åœæ­¢AIæ’­æ”¾
- æ¸…ç©ºéŸ³é¢‘æ’­æ”¾ç¼“å†²åŒº
- å‘é€å–æ¶ˆä¿¡å·ç»™æœåŠ¡å™¨

## ğŸ› ï¸ æ•…éšœæ’é™¤

### macOSéº¦å…‹é£æƒé™
å¦‚æœé‡åˆ°è¯­éŸ³æ£€æµ‹é—®é¢˜ï¼š
1. è¿è¡Œæƒé™ä¿®å¤å·¥å…·ï¼š`python macos_voice_permission_fix.py`
2. åœ¨ç³»ç»Ÿåå¥½è®¾ç½® > å®‰å…¨æ€§ä¸éšç§ > éšç§ > éº¦å…‹é£ä¸­æ·»åŠ ç»ˆç«¯åº”ç”¨
3. é‡å¯ç»ˆç«¯åº”ç”¨ç¨‹åº

### éŸ³é¢‘è®¾å¤‡é—®é¢˜
```bash
# è¿è¡ŒéŸ³é¢‘è¯Šæ–­
python audio_diagnostic.py

# æ·±åº¦è°ƒè¯•
python deep_voice_debug.py
```

### å¸¸è§é—®é¢˜
- **æ— æ³•æ£€æµ‹è¯­éŸ³**: æ£€æŸ¥éº¦å…‹é£æƒé™ï¼Œå°è¯•æ›´å¤§å£°è¯´è¯
- **è¿æ¥å¤±è´¥**: æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥
- **éŸ³é¢‘è´¨é‡å·®**: å°è¯•ä½¿ç”¨å†…ç½®éº¦å…‹é£è€Œéè“ç‰™è®¾å¤‡

## ğŸ“Š é¡¹ç›®ç»“æ„

```
FractFlow/
â”œâ”€â”€ FractFlow/                      # æ ¸å¿ƒæ¡†æ¶
â”‚   â”œâ”€â”€ agent.py                   # ä¸»è¦Agentç±»
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ models/                    # AIæ¨¡å‹é›†æˆ
â”‚   â””â”€â”€ ui/                        # ç”¨æˆ·ç•Œé¢
â”œâ”€â”€ tools/                         # å·¥å…·é›†åˆ
â”‚   â”œâ”€â”€ core/                      # æ ¸å¿ƒå·¥å…·
â”‚   â”‚   â”œâ”€â”€ qwen_realtime_voice/   # è¯­éŸ³äº¤äº’å·¥å…·
â”‚   â”‚   â”œâ”€â”€ comfyui/              # ComfyUIé›†æˆ
â”‚   â”‚   â”œâ”€â”€ file_io/              # æ–‡ä»¶æ“ä½œ
â”‚   â”‚   â””â”€â”€ ...                   # å…¶ä»–å·¥å…·
â”‚   â””â”€â”€ custom/                    # è‡ªå®šä¹‰å·¥å…·
â”œâ”€â”€ perfect_voice_chat.py          # å®Œç¾ç‰ˆè¯­éŸ³èŠå¤©
â”œâ”€â”€ audio_diagnostic.py            # éŸ³é¢‘è¯Šæ–­å·¥å…·
â””â”€â”€ config.env.example            # é…ç½®æ¨¡æ¿
```

## ğŸ¯ è¯­éŸ³äº¤äº’å·¥ä½œæµç¨‹

1. **è¿æ¥å»ºç«‹** - ä¸åƒé—®Omni APIå»ºç«‹WebSocketè¿æ¥
2. **éŸ³é¢‘åˆå§‹åŒ–** - è®¾ç½®å½•éŸ³å’Œæ’­æ”¾è®¾å¤‡
3. **å®æ—¶å½•éŸ³** - æŒç»­å½•åˆ¶ç”¨æˆ·è¯­éŸ³è¾“å…¥
4. **è¯­éŸ³æ£€æµ‹** - æœåŠ¡å™¨ç«¯VADæ£€æµ‹è¯­éŸ³æ´»åŠ¨
5. **è¯­éŸ³è¯†åˆ«** - å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬
6. **AIå¤„ç†** - ç”Ÿæˆå›å¤å†…å®¹
7. **è¯­éŸ³åˆæˆ** - å°†å›å¤è½¬æ¢ä¸ºè¯­éŸ³
8. **éŸ³é¢‘æ’­æ”¾** - æ’­æ”¾AIè¯­éŸ³å›å¤
9. **æ‰“æ–­å¤„ç†** - æ”¯æŒç”¨æˆ·éšæ—¶æ‰“æ–­AIè¯´è¯

## ğŸ”§ æŠ€æœ¯æ¶æ„

- **WebSocketé€šä¿¡**: å®æ—¶åŒå‘æ•°æ®ä¼ è¾“
- **å¤šçº¿ç¨‹å¤„ç†**: å½•éŸ³ã€å¤„ç†ã€æ’­æ”¾ç‹¬ç«‹çº¿ç¨‹
- **éŸ³é¢‘æµå¤„ç†**: PyAudio + 16kHz PCMæ ¼å¼
- **æ™ºèƒ½VAD**: æœåŠ¡å™¨ç«¯è¯­éŸ³æ´»åŠ¨æ£€æµ‹
- **ç¼“å†²ç®¡ç†**: éŸ³é¢‘æ•°æ®é˜Ÿåˆ—å’Œç¼“å†²åŒºç®¡ç†

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„è¯­éŸ³åŠŸèƒ½
```python
from tools.core.qwen_realtime_voice.qwen_realtime_voice_mcp import QwenRealtimeVoiceClient

class CustomVoiceClient(QwenRealtimeVoiceClient):
    def __init__(self):
        super().__init__()
        # è‡ªå®šä¹‰åˆå§‹åŒ–
    
    async def _handle_responses(self):
        # è‡ªå®šä¹‰å“åº”å¤„ç†
        await super()._handle_responses()
```

### è‡ªå®šä¹‰VADå‚æ•°
```python
config = {
    "turn_detection": {
        "type": "server_vad",
        "threshold": 0.2,        # è°ƒæ•´æ•æ„Ÿåº¦
        "prefix_padding_ms": 200, # è°ƒæ•´å‰ç¼€æ—¶é—´
        "silence_duration_ms": 500 # è°ƒæ•´é™éŸ³åˆ¤æ–­
    }
}
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [åƒé—®Omni](https://dashscope.aliyuncs.com/) - æä¾›å®æ—¶è¯­éŸ³äº¤äº’API
- [PyAudio](https://pypi.org/project/PyAudio/) - éŸ³é¢‘å¤„ç†åº“
- [WebSockets](https://pypi.org/project/websockets/) - WebSocketé€šä¿¡

## ğŸ“ è”ç³»æˆ‘ä»¬

å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- åˆ›å»º [Issue](https://github.com/yourusername/FractFlow/issues)
- å‘é€é‚®ä»¶åˆ°: your-email@example.com

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼
