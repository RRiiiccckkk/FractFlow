"""
åƒé—®Omniå®æ—¶è¯­éŸ³MCPå·¥å…· v2.1
æ”¯æŒå®æ—¶è¯­éŸ³æ‰“æ–­åŠŸèƒ½
"""

import asyncio
import json
import os
import uuid
import base64
import threading
import queue
import time
from typing import Dict, Any, Optional, List
from datetime import datetime
import websockets
from mcp.server.fastmcp import FastMCP
from dotenv import load_dotenv

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False
    print("Warning: pyaudio not installed. Install with: uv add pyaudio")

load_dotenv()
mcp = FastMCP("qwen_realtime_voice")

# é…ç½®
API_KEY = os.getenv("DASHSCOPE_API_KEY") or os.getenv("QWEN_API_KEY")
API_URL = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime?model=qwen-omni-turbo-realtime"

# éŸ³é¢‘å‚æ•°
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_SIZE = 1024
FORMAT = pyaudio.paInt16 if HAS_PYAUDIO else None

class QwenRealtimeVoiceClient:
    """åƒé—®Omniå®æ—¶è¯­éŸ³å®¢æˆ·ç«¯ - æ”¯æŒå®æ—¶æ‰“æ–­åŠŸèƒ½"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or API_KEY
        self.websocket = None
        self.session_id = None
        self.is_connected = False
        self.is_recording = False
        
        # éŸ³é¢‘ç›¸å…³
        if HAS_PYAUDIO:
            self.pyaudio_instance = None
            self.input_stream = None
            self.output_stream = None
        
        # é˜Ÿåˆ—å’ŒçŠ¶æ€
        self.audio_queue = queue.Queue()
        self.response_queue = queue.Queue()
        self.conversation_history = []
        
        # çº¿ç¨‹æ§åˆ¶
        self.recording_thread = None
        self.processing_thread = None
        self.stop_event = threading.Event()
        
        # å®æ—¶æ‰“æ–­åŠŸèƒ½ç›¸å…³çŠ¶æ€
        self.is_ai_speaking = False
        self.interrupt_detected = False
        self.audio_playback_thread = None
        self.audio_buffer = queue.Queue()
        self.stop_playback_event = threading.Event()
        
    async def connect(self) -> Dict[str, Any]:
        """è¿æ¥åˆ°åƒé—®Omni API"""
        try:
            print("ğŸ”— æ­£åœ¨è¿æ¥åƒé—®Omniå®æ—¶API...")
            
            headers = [
                ("Authorization", f"Bearer {self.api_key}"),
                ("User-Agent", "FractFlow-QwenOmni/2.1")
            ]
            
            # å»ºç«‹WebSocketè¿æ¥
            self.websocket = await websockets.connect(
                API_URL,
                additional_headers=headers,
                ping_interval=30,
                ping_timeout=10
            )
            
            # ç­‰å¾…ä¼šè¯å»ºç«‹
            message = await asyncio.wait_for(self.websocket.recv(), timeout=5.0)
            session_data = json.loads(message)
            
            if session_data.get("type") == "session.created":
                self.session_id = session_data["session"]["id"]
                self.is_connected = True
                
                # é…ç½®ä¼šè¯
                await self._configure_session()
                
                print(f"âœ… è¿æ¥æˆåŠŸï¼ä¼šè¯ID: {self.session_id}")
                return {"success": True, "session_id": self.session_id}
            else:
                return {"success": False, "error": "Unexpected session response"}
                
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _configure_session(self):
        """é…ç½®ä¼šè¯å‚æ•° - ä¼˜åŒ–æ‰“æ–­åŠŸèƒ½"""
        config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡è‡ªç„¶åœ°å›ç­”é—®é¢˜ã€‚ä¿æŒå›å¤ç®€æ´æ˜äº†ã€‚æ”¯æŒè¢«ç”¨æˆ·éšæ—¶æ‰“æ–­ã€‚",
                "voice": "Chelsie",
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": 0.2,  # é™ä½é˜ˆå€¼ï¼Œæ›´æ•æ„Ÿåœ°æ£€æµ‹æ‰“æ–­
                    "prefix_padding_ms": 200,  # å‡å°‘å‰ç¼€å»¶è¿Ÿ
                    "silence_duration_ms": 600  # å‡å°‘é™éŸ³åˆ¤æ–­æ—¶é—´
                },
                "temperature": 0.7,
                "max_response_output_tokens": 2048
            }
        }
        
        await self.websocket.send(json.dumps(config))
        print("âš™ï¸ ä¼šè¯é…ç½®å®Œæˆï¼ˆå·²å¯ç”¨å®æ—¶æ‰“æ–­åŠŸèƒ½ï¼‰")
    
    def init_audio(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ"""
        if not HAS_PYAUDIO:
            return {"success": False, "error": "PyAudio not available"}
        
        try:
            self.pyaudio_instance = pyaudio.PyAudio()
            
            # æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
            device_count = self.pyaudio_instance.get_device_count()
            print(f"ğŸµ å‘ç° {device_count} ä¸ªéŸ³é¢‘è®¾å¤‡")
            
            # æŸ¥æ‰¾é»˜è®¤è¾“å…¥è®¾å¤‡
            default_input = self.pyaudio_instance.get_default_input_device_info()
            print(f"ğŸ¤ é»˜è®¤è¾“å…¥è®¾å¤‡: {default_input['name']}")
            
            return {"success": True, "message": "éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ"}
            
        except Exception as e:
            return {"success": False, "error": f"éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥: {e}"}
    
    def start_recording(self) -> Dict[str, Any]:
        """å¼€å§‹å½•éŸ³"""
        if not HAS_PYAUDIO or not self.pyaudio_instance:
            audio_result = self.init_audio()
            if not audio_result["success"]:
                return audio_result
        
        try:
            # åˆ›å»ºè¾“å…¥æµ
            self.input_stream = self.pyaudio_instance.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=SAMPLE_RATE,
                input=True,
                frames_per_buffer=CHUNK_SIZE
            )
            
            self.is_recording = True
            self.stop_event.clear()
            self.stop_playback_event.clear()
            
            # å¯åŠ¨å½•éŸ³çº¿ç¨‹
            self.recording_thread = threading.Thread(target=self._recording_worker)
            self.recording_thread.start()
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.processing_thread = threading.Thread(target=self._processing_worker)
            self.processing_thread.start()
            
            # å¯åŠ¨éŸ³é¢‘æ’­æ”¾çº¿ç¨‹
            self.audio_playback_thread = threading.Thread(target=self._audio_playback_worker)
            self.audio_playback_thread.start()
            
            print("ğŸ¤ å½•éŸ³å·²å¼€å§‹ï¼ˆæ”¯æŒå®æ—¶æ‰“æ–­ï¼‰")
            return {"success": True, "message": "å½•éŸ³å¼€å§‹"}
            
        except Exception as e:
            return {"success": False, "error": f"å½•éŸ³å¯åŠ¨å¤±è´¥: {e}"}
    
    def _recording_worker(self):
        """å½•éŸ³å·¥ä½œçº¿ç¨‹"""
        print("ğŸµ å½•éŸ³çº¿ç¨‹å¯åŠ¨")
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data = self.input_stream.read(CHUNK_SIZE, exception_on_overflow=False)
                
                # æ”¾å…¥é˜Ÿåˆ—
                if not self.audio_queue.full():
                    self.audio_queue.put(audio_data)
                
                time.sleep(0.01)  # å°å»¶è¿Ÿé¿å…CPUå ç”¨è¿‡é«˜
                
            except Exception as e:
                if self.is_recording:
                    print(f"âŒ å½•éŸ³é”™è¯¯: {e}")
                break
                
        print("ğŸ›‘ å½•éŸ³çº¿ç¨‹ç»“æŸ")
    
    def _processing_worker(self):
        """éŸ³é¢‘å¤„ç†å·¥ä½œçº¿ç¨‹"""
        print("ğŸ”„ å¤„ç†çº¿ç¨‹å¯åŠ¨")
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            loop.run_until_complete(self._async_processing())
        except Exception as e:
            print(f"âŒ å¤„ç†çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            loop.close()
            print("ğŸ›‘ å¤„ç†çº¿ç¨‹ç»“æŸ")
    
    async def _async_processing(self):
        """å¼‚æ­¥éŸ³é¢‘å¤„ç†"""
        audio_chunks_sent = 0
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                # å‘é€éŸ³é¢‘æ•°æ®
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get_nowait()
                    await self._send_audio_chunk(audio_data)
                    audio_chunks_sent += 1
                    
                    if audio_chunks_sent % 100 == 0:
                        print(f"ğŸ“¤ å·²å‘é€ {audio_chunks_sent} ä¸ªéŸ³é¢‘å—")
                
                # å¤„ç†æœåŠ¡å™¨å“åº”
                await self._handle_responses()
                
                # å°å»¶è¿Ÿ
                await asyncio.sleep(0.05)
                
            except Exception as e:
                if "websocket" not in str(e).lower():
                    print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.1)
    
    async def _send_audio_chunk(self, audio_data: bytes):
        """å‘é€éŸ³é¢‘å—åˆ°æœåŠ¡å™¨"""
        try:
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            event = {
                "type": "input_audio_buffer.append",
                "audio": audio_base64
            }
            
            await self.websocket.send(json.dumps(event))
            
        except Exception as e:
            print(f"âŒ å‘é€éŸ³é¢‘å¤±è´¥: {e}")
            if "1011" in str(e):
                print("ğŸ”„ æ£€æµ‹åˆ°æœåŠ¡å™¨é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡è¿")
    
    async def _handle_responses(self):
        """å¤„ç†æœåŠ¡å™¨å“åº” - å¢å¼ºæ‰“æ–­æ£€æµ‹"""
        try:
            # éé˜»å¡æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¶ˆæ¯
            message = await asyncio.wait_for(self.websocket.recv(), timeout=0.01)
            response_data = json.loads(message)
            
            response_type = response_data.get("type", "")
            
            # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
            if response_type == "input_audio_buffer.speech_started":
                print("ğŸ¤ [ç”¨æˆ·å¼€å§‹è¯´è¯]")
                # æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯ï¼Œæ‰§è¡Œæ‰“æ–­é€»è¾‘
                if self.is_ai_speaking:
                    await self._interrupt_ai_response()
                
            elif response_type == "input_audio_buffer.speech_stopped":
                print("ğŸ”‡ [ç”¨æˆ·åœæ­¢è¯´è¯]")
                self.interrupt_detected = False
                
            elif response_type == "response.audio_transcript.delta":
                transcript = response_data.get("delta", "")
                if transcript.strip():
                    print(f"ğŸ’¬ AI: {transcript}", end="", flush=True)
                    
            elif response_type == "response.audio_transcript.done":
                print()  # æ¢è¡Œ
                
            elif response_type == "response.audio.delta":
                # å°†éŸ³é¢‘æ•°æ®åŠ å…¥æ’­æ”¾ç¼“å†²åŒº
                audio_base64 = response_data.get("delta", "")
                if audio_base64 and not self.interrupt_detected:
                    self.audio_buffer.put(audio_base64)
                    self.is_ai_speaking = True
                    
            elif response_type == "response.done":
                print("âœ… [AIå“åº”å®Œæˆ]")
                self.is_ai_speaking = False
                
            elif response_type == "conversation.item.created":
                print("ğŸ“ [å¯¹è¯é¡¹åˆ›å»º]")
                
        except asyncio.TimeoutError:
            # æ­£å¸¸æƒ…å†µï¼Œæ²¡æœ‰æ–°æ¶ˆæ¯
            pass
        except Exception as e:
            if "websocket" not in str(e).lower():
                print(f"âŒ å“åº”å¤„ç†é”™è¯¯: {e}")
    
    async def _interrupt_ai_response(self):
        """æ‰§è¡ŒAIå“åº”æ‰“æ–­"""
        print("âš¡ [æ£€æµ‹åˆ°æ‰“æ–­ï¼Œåœæ­¢AIè¯­éŸ³æ’­æ”¾]")
        self.interrupt_detected = True
        self.is_ai_speaking = False
        
        # æ¸…ç©ºéŸ³é¢‘æ’­æ”¾ç¼“å†²åŒº
        while not self.audio_buffer.empty():
            try:
                self.audio_buffer.get_nowait()
            except queue.Empty:
                break
        
        # é€šçŸ¥æœåŠ¡å™¨å–æ¶ˆå½“å‰å“åº”
        try:
            cancel_event = {
                "type": "response.cancel"
            }
            await self.websocket.send(json.dumps(cancel_event))
            print("ğŸ“¤ [å·²å‘é€å–æ¶ˆä¿¡å·ç»™æœåŠ¡å™¨]")
        except Exception as e:
            print(f"âŒ å‘é€å–æ¶ˆä¿¡å·å¤±è´¥: {e}")
    
    def _audio_playback_worker(self):
        """éŸ³é¢‘æ’­æ”¾å·¥ä½œçº¿ç¨‹"""
        print("ğŸ”Š éŸ³é¢‘æ’­æ”¾çº¿ç¨‹å¯åŠ¨")
        
        while self.is_recording and not self.stop_event.is_set():
            try:
                if not self.audio_buffer.empty() and not self.interrupt_detected:
                    audio_base64 = self.audio_buffer.get(timeout=0.1)
                    self._play_audio_sync(audio_base64)
                else:
                    time.sleep(0.01)
                    
            except queue.Empty:
                time.sleep(0.01)
            except Exception as e:
                if self.is_recording:
                    print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")
                    
        print("ğŸ›‘ éŸ³é¢‘æ’­æ”¾çº¿ç¨‹ç»“æŸ")
    
    def _play_audio_sync(self, audio_base64: str):
        """åŒæ­¥æ’­æ”¾éŸ³é¢‘ï¼ˆæ”¯æŒæ‰“æ–­ï¼‰"""
        try:
            if not HAS_PYAUDIO or self.interrupt_detected:
                return
                
            audio_data = base64.b64decode(audio_base64)
            
            # åˆ›å»ºè¾“å‡ºæµï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if not self.output_stream:
                self.output_stream = self.pyaudio_instance.open(
                    format=FORMAT,
                    channels=CHANNELS,
                    rate=SAMPLE_RATE,
                    output=True
                )
            
            # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
            if not self.interrupt_detected:
                self.output_stream.write(audio_data)
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")
    
    def stop_recording(self) -> Dict[str, Any]:
        """åœæ­¢å½•éŸ³"""
        try:
            print("ğŸ›‘ æ­£åœ¨åœæ­¢å½•éŸ³...")
            
            self.is_recording = False
            self.stop_event.set()
            self.stop_playback_event.set()
            
            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self.recording_thread and self.recording_thread.is_alive():
                self.recording_thread.join(timeout=2)
                
            if self.processing_thread and self.processing_thread.is_alive():
                self.processing_thread.join(timeout=2)
                
            if self.audio_playback_thread and self.audio_playback_thread.is_alive():
                self.audio_playback_thread.join(timeout=2)
            
            # å…³é—­éŸ³é¢‘æµ
            if self.input_stream:
                self.input_stream.stop_stream()
                self.input_stream.close()
                self.input_stream = None
                
            if self.output_stream:
                self.output_stream.stop_stream()
                self.output_stream.close()
                self.output_stream = None
            
            return {"success": True, "message": "å½•éŸ³å·²åœæ­¢"}
            
        except Exception as e:
            return {"success": False, "error": f"åœæ­¢å½•éŸ³å¤±è´¥: {e}"}
    
    async def disconnect(self) -> Dict[str, Any]:
        """æ–­å¼€è¿æ¥"""
        try:
            print("ğŸ”Œ æ­£åœ¨æ–­å¼€è¿æ¥...")
            
            # åœæ­¢å½•éŸ³
            self.stop_recording()
            
            # å…³é—­WebSocket
            if self.websocket and self.is_connected:
                await self.websocket.close()
                
            self.is_connected = False
            
            # æ¸…ç†éŸ³é¢‘èµ„æº
            if HAS_PYAUDIO and self.pyaudio_instance:
                self.pyaudio_instance.terminate()
                self.pyaudio_instance = None
            
            return {"success": True, "message": "è¿æ¥å·²æ–­å¼€"}
            
        except Exception as e:
            return {"success": False, "error": f"æ–­å¼€è¿æ¥å¤±è´¥: {e}"}

# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹
_client = None

def get_client() -> QwenRealtimeVoiceClient:
    """è·å–å®¢æˆ·ç«¯å®ä¾‹"""
    global _client
    if _client is None:
        _client = QwenRealtimeVoiceClient()
    return _client

@mcp.tool()
async def connect_to_qwen_realtime() -> str:
    """è¿æ¥åˆ°åƒé—®Omniå®æ—¶è¯­éŸ³API"""
    try:
        client = get_client()
        result = await client.connect()
        
        if result["success"]:
            return f"âœ… æˆåŠŸè¿æ¥åˆ°åƒé—®Omniå®æ—¶API\nä¼šè¯ID: {result['session_id']}"
        else:
            return f"âŒ è¿æ¥å¤±è´¥: {result.get('error', 'Unknown error')}"
            
    except Exception as e:
        return f"âŒ è¿æ¥é”™è¯¯: {str(e)}"

@mcp.tool()
async def start_voice_conversation_with_interrupt() -> str:
    """å¯åŠ¨æ”¯æŒå®æ—¶æ‰“æ–­çš„è¯­éŸ³å¯¹è¯åŠŸèƒ½"""
    try:
        client = get_client()
        
        # è¿æ¥API
        connect_result = await client.connect()
        if not connect_result["success"]:
            return f"âŒ è¿æ¥å¤±è´¥: {connect_result.get('error')}"
        
        # åˆå§‹åŒ–éŸ³é¢‘
        audio_result = client.init_audio()
        if not audio_result["success"]:
            return f"âŒ éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥: {audio_result.get('error')}"
        
        # å¼€å§‹å½•éŸ³
        record_result = client.start_recording()
        if not record_result["success"]:
            return f"âŒ å½•éŸ³å¯åŠ¨å¤±è´¥: {record_result.get('error')}"
        
        return """âœ… æ”¯æŒå®æ—¶æ‰“æ–­çš„è¯­éŸ³å¯¹è¯å·²å¯åŠ¨ï¼
        
ğŸ™ï¸ ç°åœ¨ä½ å¯ä»¥ï¼š
   â€¢ ç›´æ¥å¯¹ç€éº¦å…‹é£è¯´è¯
   â€¢ AIä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å›å¤
   â€¢ âš¡ **éšæ—¶æ‰“æ–­AIçš„å›å¤** - åªéœ€å¼€å§‹è¯´è¯å³å¯
   â€¢ ä½¿ç”¨ stop_voice_conversation() åœæ­¢å¯¹è¯
        
ğŸ’¡ æ–°åŠŸèƒ½ç‰¹æ€§ï¼š
   - ğŸ”„ å®æ—¶è¯­éŸ³æ´»åŠ¨æ£€æµ‹
   - âš¡ æ™ºèƒ½æ‰“æ–­AIå›å¤
   - ğŸµ ä¼˜åŒ–çš„éŸ³é¢‘ç¼“å†²æœºåˆ¶
   - ğŸ“¢ æ›´æ•æ„Ÿçš„è¯­éŸ³æ£€æµ‹
        
è¯·å¼€å§‹è¯´è¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä½ çš„è¯­éŸ³è¾“å…¥ï¼"""
        
    except Exception as e:
        return f"âŒ å¯åŠ¨è¯­éŸ³å¯¹è¯å¤±è´¥: {str(e)}"

@mcp.tool()
async def start_voice_conversation() -> str:
    """å¯åŠ¨å®Œæ•´çš„è¯­éŸ³å¯¹è¯åŠŸèƒ½ï¼ˆå‘åå…¼å®¹ç‰ˆæœ¬ï¼‰"""
    return await start_voice_conversation_with_interrupt()

@mcp.tool()
async def stop_voice_conversation() -> str:
    """åœæ­¢è¯­éŸ³å¯¹è¯"""
    try:
        client = get_client()
        
        # åœæ­¢å½•éŸ³
        stop_result = client.stop_recording()
        if not stop_result["success"]:
            return f"âš ï¸ åœæ­¢å½•éŸ³æ—¶å‡ºç°é—®é¢˜: {stop_result.get('error')}"
        
        # æ–­å¼€è¿æ¥
        disconnect_result = await client.disconnect()
        if not disconnect_result["success"]:
            return f"âš ï¸ æ–­å¼€è¿æ¥æ—¶å‡ºç°é—®é¢˜: {disconnect_result.get('error')}"
        
        return """âœ… è¯­éŸ³å¯¹è¯å·²åœæ­¢
        
ğŸ”‡ å·²å®Œæˆï¼š
   â€¢ åœæ­¢éŸ³é¢‘å½•åˆ¶
   â€¢ åœæ­¢AIè¯­éŸ³æ’­æ”¾
   â€¢ å…³é—­WebSocketè¿æ¥
   â€¢ æ¸…ç†éŸ³é¢‘èµ„æº"""
        
    except Exception as e:
        return f"âŒ åœæ­¢è¯­éŸ³å¯¹è¯å¤±è´¥: {str(e)}"

@mcp.tool()
def get_voice_status() -> str:
    """è·å–è¯­éŸ³å¯¹è¯çŠ¶æ€"""
    try:
        client = get_client()
        
        status = {
            "è¿æ¥çŠ¶æ€": "å·²è¿æ¥" if client.is_connected else "æœªè¿æ¥",
            "å½•éŸ³çŠ¶æ€": "å½•éŸ³ä¸­" if client.is_recording else "å·²åœæ­¢",
            "AIè¯´è¯çŠ¶æ€": "è¯´è¯ä¸­" if getattr(client, 'is_ai_speaking', False) else "æœªè¯´è¯",
            "æ‰“æ–­æ£€æµ‹": "å·²æ£€æµ‹åˆ°" if getattr(client, 'interrupt_detected', False) else "æ­£å¸¸",
            "ä¼šè¯ID": client.session_id or "æ— "
        }
        
        status_text = "ğŸ“Š å½“å‰è¯­éŸ³å¯¹è¯çŠ¶æ€ï¼š\n"
        for key, value in status.items():
            status_text += f"   â€¢ {key}: {value}\n"
        
        return status_text
        
    except Exception as e:
        return f"âŒ è·å–çŠ¶æ€å¤±è´¥: {str(e)}"

@mcp.tool()
async def test_interrupt_feature() -> str:
    """æµ‹è¯•å®æ—¶æ‰“æ–­åŠŸèƒ½"""
    try:
        client = get_client()
        
        if not client.is_connected:
            return "âŒ è¯·å…ˆè¿æ¥è¯­éŸ³æœåŠ¡"
        
        if not client.is_recording:
            return "âŒ è¯·å…ˆå¯åŠ¨è¯­éŸ³å¯¹è¯"
        
        # æ¨¡æ‹Ÿæ‰“æ–­
        if hasattr(client, '_interrupt_ai_response'):
            await client._interrupt_ai_response()
            return """âœ… æ‰“æ–­åŠŸèƒ½æµ‹è¯•å®Œæˆ
            
ğŸ§ª æµ‹è¯•ç»“æœï¼š
   â€¢ å·²è§¦å‘æ‰“æ–­é€»è¾‘
   â€¢ æ¸…ç©ºäº†éŸ³é¢‘æ’­æ”¾ç¼“å†²åŒº
   â€¢ å‘é€äº†å–æ¶ˆä¿¡å·ç»™æœåŠ¡å™¨
   
ğŸ’¡ åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œåªéœ€å¼€å§‹è¯´è¯å³å¯è‡ªåŠ¨è§¦å‘æ‰“æ–­åŠŸèƒ½"""
        else:
            return "âŒ æ‰“æ–­åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®¢æˆ·ç«¯ç‰ˆæœ¬"
            
    except Exception as e:
        return f"âŒ æµ‹è¯•æ‰“æ–­åŠŸèƒ½å¤±è´¥: {str(e)}"

if __name__ == "__main__":
    # å¯åŠ¨MCPæœåŠ¡å™¨
    mcp.run() 