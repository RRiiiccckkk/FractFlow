# 千问Omni实时语音打断功能指南

## 📢 功能概述

千问Omni实时语音对话系统v2.1现在支持**实时语音打断**功能，允许用户在AI说话过程中随时打断AI的回复，实现更自然的对话体验。

## ⚡ 新功能特性

### 🎯 智能语音活动检测(VAD)
- **实时监听**：系统持续监听用户的语音输入
- **敏感检测**：降低VAD阈值(0.3→0.2)，提高语音检测敏感度
- **快速响应**：减少前缀延迟(300ms→200ms)和静音判断时间(800ms→600ms)

### 🛑 AI响应打断机制
- **即时停止**：检测到用户开始说话时立即停止AI语音播放
- **缓冲清理**：自动清空音频播放缓冲区，避免延迟播放
- **服务器同步**：发送取消信号给服务器，中断当前AI响应生成

### 🎵 优化的音频处理架构
- **独立播放线程**：音频播放在独立线程中进行，支持实时打断
- **智能缓冲管理**：动态管理音频缓冲区，优化内存使用
- **多线程同步**：录音、处理、播放三个线程协调工作

## 🚀 使用方法

### 快速启动
```bash
# 方法1：使用简化启动脚本
python qwen_voice_chat.py

# 方法2：使用专门的打断测试脚本
python test_voice_interrupt.py

# 方法3：使用Agent交互模式
python tools/core/qwen_realtime_voice/qwen_realtime_voice_agent.py --interactive
```

### MCP工具调用
```python
# 启动支持打断的语音对话
await start_voice_conversation_with_interrupt()

# 向后兼容的启动方式（自动支持打断）
await start_voice_conversation()

# 手动测试打断功能
await test_interrupt_feature()

# 查看实时状态
get_voice_status()
```

## 🎤 实际使用指南

### 基本对话流程
1. **启动系统**：运行任一启动脚本
2. **开始对话**：直接对着麦克风说话
3. **AI回复**：系统自动识别并生成语音回复
4. **实时打断**：在AI说话过程中，直接开始说话即可打断

### 打断操作示例
```
用户："请详细介绍一下人工智能的发展历史"
AI开始回复："人工智能的发展可以追溯到20世纪50年代..."
用户：（在AI说话中途）"等等，我想问一个更具体的问题"
系统：⚡ [检测到打断，停止AI语音播放]
AI：停止当前回复，准备接收新的问题
```

### 最佳实践建议
- **清晰发音**：确保语音输入清晰，便于VAD检测
- **适当音量**：保持适中的说话音量
- **自然对话**：像正常对话一样，想打断时直接说话
- **观察提示**：注意系统显示的状态消息

## 🔍 系统状态监控

### 状态指示器
- `🎤 [用户开始说话]` - 检测到用户语音输入开始
- `🔇 [用户停止说话]` - 检测到用户语音输入结束
- `⚡ [检测到打断，停止AI语音播放]` - 执行打断操作
- `💬 AI: [转录内容]` - AI回复的文字转录
- `✅ [AI响应完成]` - AI当前回复结束

### 状态查询
```bash
# 在交互模式中输入
status

# 显示结果示例
📊 连接状态: 已连接
🎤 录音状态: 录音中
🤖 AI说话状态: 说话中
⚡ 打断检测: 正常
🆔 会话ID: session_xxx
```

## 🛠️ 技术实现详情

### 架构改进
```python
class QwenRealtimeVoiceClient:
    def __init__(self):
        # 新增打断功能相关状态
        self.is_ai_speaking = False
        self.interrupt_detected = False
        self.audio_playback_thread = None
        self.audio_buffer = queue.Queue()
        self.stop_playback_event = threading.Event()
```

### 关键方法
- `_interrupt_ai_response()`: 执行打断逻辑
- `_audio_playback_worker()`: 独立音频播放线程
- `_play_audio_sync()`: 支持打断的同步播放
- `_handle_responses()`: 增强的响应处理，包含打断检测

### VAD参数优化
```json
{
  "turn_detection": {
    "type": "server_vad",
    "threshold": 0.2,        // 降低阈值，更敏感
    "prefix_padding_ms": 200, // 减少前缀延迟
    "silence_duration_ms": 600 // 减少静音判断时间
  }
}
```

## 🧪 测试和调试

### 专用测试脚本
```bash
python test_voice_interrupt.py
```

测试脚本功能：
- 🔗 自动连接API
- 🎵 初始化音频系统
- 🚀 启动语音对话
- 🧪 提供测试场景建议
- 📊 实时状态监控
- 🛠️ 手动打断测试

### 推荐测试场景
1. **长回答问题**：
   - "请详细介绍一下人工智能的发展历史"
   - "能否解释一下量子计算的原理？"
   - "请讲一个长故事"

2. **打断测试**：
   - 在AI回答过程中开始说话
   - 观察系统是否显示打断消息
   - 确认AI是否立即停止播放

3. **连续对话**：
   - 多轮对话测试
   - 频繁打断测试
   - 长时间对话稳定性测试

## ❓ 常见问题

### Q: 打断功能不工作？
A: 检查以下几点：
- 确保使用v2.1版本的代码
- 确认VAD阈值设置正确
- 检查麦克风权限和音量设置
- 观察是否有"检测到打断"的消息

### Q: 打断检测过于敏感？
A: 可以调整VAD参数：
```python
"threshold": 0.3,  # 提高阈值降低敏感度
"silence_duration_ms": 800  # 增加静音判断时间
```

### Q: 音频播放有延迟？
A: 这是正常现象，实时打断功能会稍微增加播放延迟，但换来的是更好的交互体验。

### Q: 系统资源占用高？
A: 新增的音频播放线程会增加一些CPU使用，这是为了实现实时打断的必要开销。

## 🎯 未来改进方向

1. **更智能的VAD**：使用机器学习优化语音活动检测
2. **情感感知打断**：根据对话情感调整打断敏感度
3. **多人对话支持**：支持多人场景下的智能打断
4. **可配置参数**：允许用户自定义VAD参数
5. **音频质量优化**：减少打断时的音频断续感

## 💡 总结

千问Omni实时语音打断功能为语音对话带来了更自然、更流畅的交互体验。通过智能的语音活动检测和优化的音频处理架构，用户可以像真实对话一样随时打断AI的回复，实现真正的实时交互。

**立即体验：**
```bash
python qwen_voice_chat.py
```

开始享受更自然的AI语音对话体验吧！🎉 