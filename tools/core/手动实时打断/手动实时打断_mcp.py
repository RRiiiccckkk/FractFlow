#!/usr/bin/env python3
"""
FractFlow æ‰‹åŠ¨å®æ—¶æ‰“æ–­è¯­éŸ³æ§åˆ¶ - MCPæœåŠ¡å™¨ç‰ˆ
åŸºäºåƒé—®Omniå®æ—¶è¯­éŸ³APIï¼Œæ”¯æŒç«‹å³æ‰“æ–­AIå›ç­”åŠŸèƒ½
"""

import asyncio
import json
import logging
from mcp.server.models import InitializationOptions
import mcp.types as types
from mcp.server import NotificationOptions, Server
from mcp.server.stdio import stdio_server
from typing import Any, Sequence
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„æ”¯æŒ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥æ‰‹åŠ¨å®æ—¶æ‰“æ–­Agent
from tools.core.æ‰‹åŠ¨å®æ—¶æ‰“æ–­.æ‰‹åŠ¨å®æ—¶æ‰“æ–­_agent import SimpleManualVoiceController

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("æ‰‹åŠ¨å®æ—¶æ‰“æ–­_mcp")

# åˆ›å»ºMCPæœåŠ¡å™¨
server = Server("æ‰‹åŠ¨å®æ—¶æ‰“æ–­_mcp")

# å…¨å±€å˜é‡å­˜å‚¨æ§åˆ¶å™¨å®ä¾‹
voice_controller = None

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·"""
    return [
        types.Tool(
            name="start_manual_interrupt_voice_control",
            description="å¯åŠ¨æ‰‹åŠ¨å®æ—¶æ‰“æ–­è¯­éŸ³æ§åˆ¶åŠ©æ‰‹",
            inputSchema={
                "type": "object",
                "properties": {
                    "enable_context": {
                        "type": "boolean",
                        "description": "æ˜¯å¦å¯ç”¨å¯¹è¯ä¸Šä¸‹æ–‡è®°å¿†",
                        "default": True
                    },
                    "voice_mode": {
                        "type": "string", 
                        "enum": ["default", "ni"],
                        "description": "è¯­éŸ³æ¨¡å¼ï¼šdefault(é»˜è®¤éŸ³è‰²) æˆ– ni(å€ªæ ¡éŸ³è‰²)",
                        "default": "default"
                    }
                },
                "required": []
            },
        ),
        types.Tool(
            name="interrupt_ai_response",
            description="ç«‹å³æ‰“æ–­AIçš„å›ç­”",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            },
        ),
        types.Tool(
            name="start_recording",
            description="å¼€å§‹å½•éŸ³",
            inputSchema={
                "type": "object", 
                "properties": {},
                "required": []
            },
        ),
        types.Tool(
            name="stop_recording_and_send",
            description="åœæ­¢å½•éŸ³å¹¶å‘é€ç»™AI",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            },
        ),
        types.Tool(
            name="get_conversation_status",
            description="è·å–å½“å‰å¯¹è¯çŠ¶æ€",
            inputSchema={
                "type": "object",
                "properties": {},
                "required": []
            },
        )
    ]

@server.call_tool()
async def handle_call_tool(
    name: str, arguments: dict[str, Any] | None
) -> list[types.TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    global voice_controller
    
    try:
        if name == "start_manual_interrupt_voice_control":
            # å¯åŠ¨æ‰‹åŠ¨å®æ—¶æ‰“æ–­è¯­éŸ³æ§åˆ¶åŠ©æ‰‹
            enable_context = arguments.get("enable_context", True) if arguments else True
            voice_mode = arguments.get("voice_mode", "default") if arguments else "default"
            
            if voice_controller is None:
                voice_controller = SimpleManualVoiceController()
            
            # åˆå§‹åŒ–è¿æ¥
            connect_result = await voice_controller.connect()
            if not connect_result["success"]:
                return [types.TextContent(
                    type="text",
                    text=f"âŒ è¿æ¥å¤±è´¥: {connect_result['error']}"
                )]
            
            # åˆå§‹åŒ–éŸ³é¢‘
            audio_result = voice_controller.setup_audio()
            if not audio_result["success"]:
                return [types.TextContent(
                    type="text",
                    text=f"âŒ éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥: {audio_result['error']}"
                )]
            
            status_text = f"""âœ… æ‰‹åŠ¨å®æ—¶æ‰“æ–­è¯­éŸ³æ§åˆ¶åŠ©æ‰‹å·²å¯åŠ¨ï¼

ğŸ“‹ æ“ä½œè¯´æ˜ï¼š
   â€¢ ä½¿ç”¨ start_recording å¼€å§‹å½•éŸ³
   â€¢ ä½¿ç”¨ stop_recording_and_send åœæ­¢å½•éŸ³å¹¶å‘é€  
   â€¢ ä½¿ç”¨ interrupt_ai_response ç«‹å³æ‰“æ–­AIå›ç­”
   â€¢ ä½¿ç”¨ get_conversation_status æŸ¥çœ‹å¯¹è¯çŠ¶æ€

ğŸ¯ ç‰¹è‰²åŠŸèƒ½ï¼š
   â€¢ âš¡ ç«‹å³æ‰“æ–­AIå›ç­”ï¼Œæ— å»¶è¿Ÿ
   â€¢ ğŸ§  æ™ºèƒ½å¯¹è¯ä¸Šä¸‹æ–‡è®°å¿†
   â€¢ ğŸ”Š é«˜è´¨é‡å®æ—¶è¯­éŸ³äº¤äº’
   â€¢ ğŸ“Š å®Œæ•´å†…å­˜ç›‘æ§å’Œç®¡ç†

ğŸ”§ å½“å‰é…ç½®ï¼š
   â€¢ è¯­éŸ³æ¨¡å¼: {voice_mode}
   â€¢ ä¸Šä¸‹æ–‡è®°å¿†: {'å¯ç”¨' if enable_context else 'ç¦ç”¨'}
   â€¢ ä¼šè¯ID: {voice_controller.session_id}
"""
            
            return [types.TextContent(type="text", text=status_text)]
            
        elif name == "interrupt_ai_response":
            # ç«‹å³æ‰“æ–­AIå›ç­”
            if voice_controller is None:
                return [types.TextContent(
                    type="text", 
                    text="âŒ è¯·å…ˆå¯åŠ¨è¯­éŸ³æ§åˆ¶åŠ©æ‰‹"
                )]
            
            if voice_controller.is_ai_speaking:
                await voice_controller._interrupt_ai()
                return [types.TextContent(
                    type="text",
                    text="âš¡ AIå·²è¢«ç«‹å³æ‰“æ–­"
                )]
            else:
                return [types.TextContent(
                    type="text",
                    text="â„¹ï¸ AIå½“å‰æœªåœ¨è¯´è¯ï¼Œæ— éœ€æ‰“æ–­"
                )]
                
        elif name == "start_recording":
            # å¼€å§‹å½•éŸ³
            if voice_controller is None:
                return [types.TextContent(
                    type="text",
                    text="âŒ è¯·å…ˆå¯åŠ¨è¯­éŸ³æ§åˆ¶åŠ©æ‰‹"
                )]
            
            if voice_controller.is_recording:
                return [types.TextContent(
                    type="text",
                    text="âš ï¸ å·²åœ¨å½•éŸ³ä¸­ï¼Œè¯·å…ˆåœæ­¢å½“å‰å½•éŸ³"
                )]
            
            voice_controller._start_recording()
            return [types.TextContent(
                type="text", 
                text="ğŸ¤ å½•éŸ³å·²å¼€å§‹ï¼Œè¯·è¯´è¯..."
            )]
            
        elif name == "stop_recording_and_send":
            # åœæ­¢å½•éŸ³å¹¶å‘é€
            if voice_controller is None:
                return [types.TextContent(
                    type="text",
                    text="âŒ è¯·å…ˆå¯åŠ¨è¯­éŸ³æ§åˆ¶åŠ©æ‰‹"
                )]
                
            if not voice_controller.is_recording:
                return [types.TextContent(
                    type="text",
                    text="âš ï¸ å½“å‰æœªåœ¨å½•éŸ³ï¼Œè¯·å…ˆå¼€å§‹å½•éŸ³"
                )]
            
            voice_controller._stop_recording()
            return [types.TextContent(
                type="text",
                text="ğŸ“¤ å½•éŸ³å·²åœæ­¢å¹¶å‘é€ï¼Œç­‰å¾…AIå›ç­”..."
            )]
            
        elif name == "get_conversation_status":
            # è·å–å¯¹è¯çŠ¶æ€
            if voice_controller is None:
                return [types.TextContent(
                    type="text",
                    text="âŒ è¯­éŸ³æ§åˆ¶åŠ©æ‰‹æœªå¯åŠ¨"
                )]
            
            # è·å–å†…å­˜çŠ¶æ€
            memory_status = voice_controller._memory_monitor.check_memory_status()
            health_status = voice_controller._health_checker.check_system_health()
            
            # è·å–å¯¹è¯ç¼“å­˜ä¿¡æ¯
            cache_info = ""
            if voice_controller.conversation_cache:
                cache_stats = voice_controller.conversation_cache.get_session_stats()
                cache_info = f"""
ğŸ“š å¯¹è¯ç¼“å­˜ä¿¡æ¯ï¼š
   â€¢ æ€»è½®æ•°: {cache_stats['total_turns']}
   â€¢ ä¼šè¯æ—¶é•¿: {cache_stats['duration_minutes']:.1f}åˆ†é’Ÿ
   â€¢ ç”¨æˆ·æ€»å­—æ•°: {cache_stats['user_total_chars']}
   â€¢ AIæ€»å­—æ•°: {cache_stats['ai_total_chars']}"""
            
            status_text = f"""ğŸ“Š æ‰‹åŠ¨å®æ—¶æ‰“æ–­è¯­éŸ³æ§åˆ¶çŠ¶æ€

ğŸ”— è¿æ¥çŠ¶æ€: {'âœ… å·²è¿æ¥' if voice_controller.is_connected else 'âŒ æœªè¿æ¥'}
ğŸ¤ å½•éŸ³çŠ¶æ€: {'ğŸŸ¢ å½•éŸ³ä¸­' if voice_controller.is_recording else 'âšª ç©ºé—²'}  
ğŸ¤– AIçŠ¶æ€: {'ğŸŸ¢ æ­£åœ¨å›ç­”' if voice_controller.is_ai_speaking else 'âšª ç©ºé—²'}
ğŸ†” ä¼šè¯ID: {voice_controller.session_id or 'æœªåˆ†é…'}

ğŸ“Š ç³»ç»ŸçŠ¶æ€ï¼š
   â€¢ å†…å­˜ä½¿ç”¨: {memory_status['current_mb']:.1f}MB (å³°å€¼: {memory_status['peak_mb']:.1f}MB)
   â€¢ çº¿ç¨‹æ•°é‡: {health_status['thread_count']}
   â€¢ ç³»ç»Ÿå¥åº·: {'âœ… æ­£å¸¸' if health_status['healthy'] else 'âš ï¸ ' + health_status['warning']}
{cache_info}

âš¡ åŠŸèƒ½çŠ¶æ€ï¼š
   â€¢ ç«‹å³æ‰“æ–­: âœ… å¯ç”¨
   â€¢ å®æ—¶å­—å¹•: âœ… å¯ç”¨
   â€¢ å†…å­˜ç›‘æ§: âœ… è¿è¡Œä¸­
"""
            
            return [types.TextContent(type="text", text=status_text)]
        
        else:
            return [types.TextContent(
                type="text",
                text=f"âŒ æœªçŸ¥å·¥å…·: {name}"
            )]
            
    except Exception as e:
        logger.error(f"å·¥å…·è°ƒç”¨é”™è¯¯: {e}")
        return [types.TextContent(
            type="text",
            text=f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}"
        )]

async def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨æ ‡å‡†è¾“å…¥è¾“å‡ºè¿è¡ŒMCPæœåŠ¡å™¨
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="æ‰‹åŠ¨å®æ—¶æ‰“æ–­_mcp",
                server_version="1.0.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(main()) 